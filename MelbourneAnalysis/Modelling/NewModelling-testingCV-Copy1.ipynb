{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "<u>Tests using the following models :</u>\n",
    "* Linear regression\n",
    "* Random forest regressor\n",
    "* Ridge and Lasso Regularization (add on to linear modelling?)\n",
    "\n",
    "<u> Tests using the following variables:</u>\n",
    "* Weather variables (rain, temperature, windspeed)\n",
    "* Time variables (Day of week, month, year, time of day, public holiday)\n",
    "* Sensor environment variables:\n",
    "    * Sensor_id\n",
    "    * Betweenness of the street \n",
    "    * Buildings in proximity to the sensor\n",
    "    * Landmarks in proximity to the sensor  \n",
    "    * Furniture in proximity to the sensor    \n",
    "    * Lights in proximity to the sensor   \n",
    "\n",
    "\n",
    "Normalise variables: should this be with MinMax or StandardScaler??\n",
    "\n",
    "\n",
    "Process:\n",
    "* Keep only data from sensor's with relatively complete data\n",
    "* Split data into training ( 75%) and test (25%)\n",
    "* Define the models to use in testing (linear regression, random forest, xgboost)\n",
    "* Define the error metrics to use in evaluating the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, mean_squared_error,r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time as thetime\n",
    "from sklearn.model_selection import cross_validate\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from time import time\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "# To display tables in HTML output\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "from Functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time()\n",
    "# model_output = cross_validate(model, Xfull, Yfull, cv=10, scoring=error_metrics ,return_estimator=True, error_score=\"raise\")\n",
    "# end = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = permutation_importance(model_output['estimator'][0], Xfull,Yfull, n_repeats=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(feature_importances) \n",
    "# len(r.importances_mean.argsort()[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import eli5\n",
    "# from eli5.sklearn import PermutationImportance\n",
    "\n",
    "# perm = PermutationImportance(model_output['estimator'][0], random_state=1).fit(Xfull, Yfull)\n",
    "# eli5.show_weights(perm, feature_names = Yfull.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_with_cv(model,model_name, metrics, cv, Xfull, Yfull, regex_name, regex_pattern):\n",
    "    print(\"Running {} model, variables include {}\".format(model_name,  regex_name))\n",
    "\n",
    "    # Filter columns using the regex pattern in function input\n",
    "    Xfull = Xfull[Xfull.columns.drop(list(Xfull.filter(regex=regex_pattern)))].copy()\n",
    "    # Get list of all features\n",
    "    feature_list = list(Xfull.columns)\n",
    "    \n",
    "    # Scaling!?!?!?\n",
    "    scaler = StandardScaler()\n",
    "    Xfull = pd.DataFrame(scaler.fit_transform(Xfull), columns=X_train.columns)\n",
    "    Xfull = pd.DataFrame(scaler.transform(Xfull), columns=X_test.columns)\n",
    "    \n",
    "    # Perform cross validation, time how long it takes\n",
    "    start = time()\n",
    "    model_output = cross_validate(model, Xfull, Yfull, cv=cv, scoring=metrics ,return_estimator=True, error_score=\"raise\")\n",
    "    end = time()\n",
    "    \n",
    "    #  Create a dataframe containng scores for each performance metric\n",
    "    df =pd.DataFrame({'mae': round(abs(model_output['test_neg_mean_absolute_error'].mean()),2), \n",
    "         'r2': round(abs(model_output['test_r2'].mean()),2), 'rmse': round(abs(model_output['test_neg_root_mean_squared_error'].mean()),2)},\n",
    "                     index =[\"{}_{}\".format(model_name, regex_name)])\n",
    "    \n",
    "    # Get the estimators \n",
    "    estimators = model_output['estimator']\n",
    "    \n",
    "    print('Ran in {} minutes'.format(round((end - start)/60),2))\n",
    "    return [estimators, df, feature_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.inspection import permutation_importance\n",
    "# r = permutation_importance(rf_model, X_val, y_val, n_repeats=30, random_state=0)\n",
    "\n",
    "# import eli5\n",
    "# from eli5.sklearn import PermutationImportance\n",
    "\n",
    "# perm = PermutationImportance(rf_model, random_state=1).fit(X_test, Y_test)\n",
    "# eli5.show_weights(perm, feature_names = val_x.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_model_with_cv(model,model_name, metrics, cv, Xfull, Yfull, regex_name, regex_pattern):\n",
    "#     print(\"Running {} model, variables include {}\".format(model_name,  regex_name))\n",
    "\n",
    "#     # Filter columns using the regex pattern in function input\n",
    "#     Xfull = Xfull[Xfull.columns.drop(list(Xfull.filter(regex=regex_pattern)))].copy()\n",
    "#     # Get list of all features\n",
    "#     feature_list = list(Xfull.columns)\n",
    "    \n",
    "#     # Perform cross validation, time how long it takes\n",
    "#     start = time()\n",
    "#     model_output = cross_validate(model, Xfull, Yfull, cv=cv, scoring=metrics ,return_estimator=True, error_score=\"raise\")\n",
    "#     end = time()\n",
    "    \n",
    "#     #  Create a dataframe containng scores for each performance metric\n",
    "#     df =pd.DataFrame({'mae': round(abs(model_output['test_neg_mean_absolute_error'].mean()),2), \n",
    "#          'r2': round(abs(model_output['test_r2'].mean()),2), 'rmse': round(abs(model_output['test_neg_root_mean_squared_error'].mean()),2)},\n",
    "#                      index =[\"{}_{}\".format(model_name, regex_name)])\n",
    "    \n",
    "#     # Get the estimators \n",
    "#     estimators = model_output['estimator']\n",
    "    \n",
    "#     print('Ran in {} minutes'.format(round((end - start)/60),2))\n",
    "#     return [estimators, df, feature_list]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in formatted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"formatted_data_for_modelling.csv\", index_col = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keep only sensors with relatively complete data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Filter to include just sensors which we know have quite complete data \n",
    "data = data[data['sensor_id'].isin([2,6,9,10,14,18])]\n",
    "data.reset_index(inplace=True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data.drop(['Pressure', 'Humidity'],axis=1) # seem obviously irrelevant\n",
    "data = data.drop(['sensor_id'],axis=1) # don't want this included\n",
    "# Get rid of columns in which none of the sensors have a value\n",
    "for column in data.columns:\n",
    "    if np.nanmax(data[column]) ==0:\n",
    "        del data[column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for modelling - split into predictor/predictand variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The predictor variables\n",
    "Xfull = data.drop(['hourly_counts'], axis =1)\n",
    "# Xfull['random'] = np.random.random(size=len(Xfull))\n",
    "\n",
    "# The variable to be predicted\n",
    "Yfull = data['hourly_counts'].values\n",
    "\n",
    "# Split data into training and test sets (Xfull/Yfull aren't used again, so these don't need to be scaled)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(Xfull, Yfull, test_size=0.75, random_state=123)\n",
    "\n",
    "#### Standardize both training and testing data\n",
    "scaler = StandardScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define models (linear regression, random forest and XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LinearRegression()\n",
    "rf_model = RandomForestRegressor(n_estimators = 500, random_state = 1, n_jobs = 64)\n",
    "xgb_model = XGBRegressor(random_state=1, n_jobs = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run models with cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the error metrics for the cross-validation to return, and the parameters of the cross validatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_metrics = ['neg_mean_absolute_error', 'r2', 'neg_root_mean_squared_error']\n",
    "cv_parameters = KFold(n_splits=10, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define regex's to remove columns not needed in various splits of removing column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_regex_dict = {'withsubtypes':'buildings$|furniture$|landmarks$',\n",
    "                     'nosubtyes':'buildings_|furniture_|landmarks_|sensor_id',\n",
    "                     'time_and_weather':'buildings|furniture|landmarks|h_|lights|avg_n_floors|betweenness',\n",
    "                      'just_location_features':'buildings$|furniture$|landmarks$|school_holiday|public_holiday|Temp|Humidity|Pressure|Rain|WindSpeed|Sin|Cos'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loop through each combination of the models, and the variables to include in the modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running linear_regression model, variables include withsubtypes\n",
      "Ran in 0 minutes\n",
      "Running linear_regression model, variables include nosubtyes\n",
      "Ran in 0 minutes\n",
      "Running linear_regression model, variables include time_and_weather\n",
      "Ran in 0 minutes\n",
      "Running linear_regression model, variables include just_location_features\n",
      "Ran in 0 minutes\n",
      "Running xgboost model, variables include withsubtypes\n",
      "Ran in 2 minutes\n",
      "Running xgboost model, variables include nosubtyes\n",
      "Ran in 1 minutes\n",
      "Running xgboost model, variables include time_and_weather\n",
      "Ran in 1 minutes\n",
      "Running xgboost model, variables include just_location_features\n",
      "Ran in 1 minutes\n"
     ]
    }
   ],
   "source": [
    "# Dataframe to store the scores for each model\n",
    "error_metric_scores = pd.DataFrame()\n",
    "\n",
    "# Dictionary to store dataframes of feature importance scores\n",
    "feature_importance_scores ={}\n",
    "\n",
    "models_dict = {\"linear_regression\": lr_model, \"xgboost\":xgb_model}\n",
    "for model_name,model in models_dict.items():\n",
    "    for regex_name, regex in column_regex_dict.items():\n",
    "        # Run the model: return the estimators and a dataframe containing evaluation metrics\n",
    "        estimators, error_metrics_df, feature_list = run_model_with_cv(model, model_name, error_metrics, cv_parameters, Xfull, Yfull, regex_name, regex) \n",
    "        # Add evaluation metric scores for this model to the dataframe containing the metrics for each model\n",
    "        error_metric_scores = error_metric_scores.append(error_metrics_df)\n",
    "        \n",
    "        # Create dataframe of feature importances (no feature importances for linear regression)\n",
    "        if model_name != 'linear_regression':\n",
    "            feature_importances = pd.DataFrame(index =[feature_list])\n",
    "            for idx,estimator in enumerate(estimators):\n",
    "                    feature_importances['Estimator{}'.format(idx)] = estimators[idx].feature_importances_\n",
    "            feature_importance_scores[\"{}_{}\".format(model_name, regex_name)] = feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mae</th>\n",
       "      <th>r2</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>linear_regression_withsubtypes</th>\n",
       "      <td>260.30</td>\n",
       "      <td>0.48</td>\n",
       "      <td>354.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear_regression_nosubtyes</th>\n",
       "      <td>264.22</td>\n",
       "      <td>0.45</td>\n",
       "      <td>363.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear_regression_time_and_weather</th>\n",
       "      <td>305.05</td>\n",
       "      <td>0.25</td>\n",
       "      <td>425.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear_regression_just_location_features</th>\n",
       "      <td>332.51</td>\n",
       "      <td>0.18</td>\n",
       "      <td>443.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost_withsubtypes</th>\n",
       "      <td>99.31</td>\n",
       "      <td>0.87</td>\n",
       "      <td>177.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost_nosubtyes</th>\n",
       "      <td>119.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>209.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost_time_and_weather</th>\n",
       "      <td>275.87</td>\n",
       "      <td>0.33</td>\n",
       "      <td>401.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost_just_location_features</th>\n",
       "      <td>330.65</td>\n",
       "      <td>0.19</td>\n",
       "      <td>442.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             mae    r2    rmse\n",
       "linear_regression_withsubtypes            260.30  0.48  354.47\n",
       "linear_regression_nosubtyes               264.22  0.45  363.75\n",
       "linear_regression_time_and_weather        305.05  0.25  425.36\n",
       "linear_regression_just_location_features  332.51  0.18  443.75\n",
       "xgboost_withsubtypes                       99.31  0.87  177.73\n",
       "xgboost_nosubtyes                         119.82  0.82  209.14\n",
       "xgboost_time_and_weather                  275.87  0.33  401.24\n",
       "xgboost_just_location_features            330.65  0.19  442.23"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_metric_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit best perfomring model and get feature importances?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataframe containing the feature importances from each of the estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the best model  \n",
    "Use k-fold cross validation to evaluate a range of regression algorithms on the training data. Use a pipeline for evaluation which first scales the (weather) data. Print the results and assess which models perform best.\n",
    "\n",
    "The following models were trialled:\n",
    "\n",
    "* Decision Tree\n",
    "* Random Forest\n",
    "* Extra Trees\n",
    "* Dummy Regressor\n",
    "* Elastic Net CV\n",
    "* Passive Aggressive\n",
    "* RANSAC\n",
    "* SGD\n",
    "* TheilSen (dropped in code below because it takes too long)\n",
    "* K Neighbours\n",
    "* LinearRegression\n",
    "* XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a list of all the models to use\n",
    "# Models = {'LinearRegression': LinearRegression,'DecisionTree' : DecisionTreeRegressor,\n",
    "#           'RandomForest': RandomForestRegressor, 'ExtraTrees' : ExtraTreesRegressor,\n",
    "#           'DummyRegressor' :DummyRegressor, 'ElasticNetCV' : ElasticNetCV, \n",
    "#           'PassiveAggressive' : PassiveAggressiveRegressor, #RANSAC': RANSACRegressor, # This one is terrible too\n",
    "#           'SGD': SGDRegressor, #'TheilSen': TheilSenRegressor, # Drop this - it isn't great and takes too long\n",
    "#           'KN': KNeighborsRegressor}#, 'XGBoost': xgb.XGBRegressor}\n",
    " \n",
    "# # Now just run each model, but do this in multiple processes simultaneously to save time    \n",
    "# # Now call that function simultaneously for each model\n",
    "# p = Pool(processes=None) # A pool of processes (one for each core)\n",
    "# results = p.map(run_model, [(name, model_type) for name, model_type in Models.items()])\n",
    "\n",
    "# # Sort the results by median mse (that's item 5 in the tuple)\n",
    "# results.sort(key=lambda x: x[5], reverse=True)\n",
    "\n",
    "# # Put the results in a nice dictionary and print them\n",
    "# results_dict = {}\n",
    "# txt = \"<table><thead><td>Name</td><td>Median R2</td><td>Median MSE</td><td>runtime (sec)</td></thead>\"\n",
    "# for name, model, all_r2, r2, all_mse, mse, runtime in results:\n",
    "#     txt += \"<tr><td>{}</td><td>{}</td><td>{}</td><td>{}</td></tr>\".format(name, r2, mse, runtime)\n",
    "#     results_dict[name] = (model, all_r2, r2, all_mse, mse, runtime)\n",
    "# txt += \"</table>\"\n",
    "# display(HTML(txt)) # print as html\n",
    "\n",
    "# min_mse = min([mse for (name, model, all_r2, r2, all_mse, mse, runtime) in results])\n",
    "               \n",
    "# x =  [ name for (name, model, all_r2, r2, all_mse, mse, runtime) in results]\n",
    "# y1 = [ mse-min_mse   for (name, model, all_r2, r2, all_mse, mse, runtime) in results]\n",
    "# y2 = [ r2 if r2 > 0 else 0 for (name, model, all_r2, r2, all_mse, mse, runtime) in results]\n",
    "\n",
    "# fig, (ax1,ax2) = plt.subplots(1, 2, figsize=(15, 7))\n",
    "\n",
    "# ax1.set_title(\"MSE\")\n",
    "# #ax1.invert_yaxis()\n",
    "# ax1.bar(range(len(x)), y1)\n",
    "# ax1.set_xticks(range(len(x)))\n",
    "# ax1.set_xticklabels(x, rotation=90)\n",
    "# ax1.set_ylim([27000000000, 29000000000])\n",
    "\n",
    "# ax2.set_title(\"R^2\")\n",
    "# ax2.bar(range(len(x)), y2)\n",
    "# ax2.set_xticks(range(len(x)))\n",
    "# ax2.set_xticklabels(x, rotation=90)\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# #del x,y1, y2\n",
    "\n",
    "# ## Set up a dictionary containing the hyperparameters we want to tune\n",
    "# hyperparameters_rf = { 'randomforestregressor__max_features' : ['auto', 'sqrt', 'log2'],\n",
    "#                   'randomforestregressor__max_depth': [None, 5, 3, 1]}\n",
    "# # hyperparameters_xgb = {'xgbregressor__max_depth': range(1, 11, 2),\n",
    "# #                    'xgbregressor__n_estimators' : range(50, 400, 50),\n",
    "# #                    'xgbregressor__learning_rate' : [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]}\n",
    "# hyperparameters_lr = {}\n",
    "\n",
    "# # Set up the pipeline containing the scalers\n",
    "# pipeline_rf = make_pipeline(MinMaxScaler(feature_range = (0,1)), \n",
    "#                          RandomForestRegressor(n_estimators=100))\n",
    "# # pipeline_xgb = make_pipeline(MinMaxScaler(feature_range = (0,1)),\n",
    "# #                          xgb.XGBRegressor(n_estimators=100))\n",
    "# pipeline_lr = make_pipeline(MinMaxScaler(feature_range = (0,1)),\n",
    "#                          LinearRegression())\n",
    "\n",
    "# # Store the scores in a results dictionary (and print them)\n",
    "# final_results = {}\n",
    "# for model_values in [(pipeline_rf,  hyperparameters_rf,  'RandomForest'),\n",
    "# #                      (pipeline_xgb, hyperparameters_xgb, 'XGBoost'),\n",
    "#                      (pipeline_lr,  hyperparameters_lr,  'LinearRegression')]:\n",
    "    \n",
    "#     clf = GridSearchCV(model_values[0], model_values[1], \n",
    "#                        #cv = None, # Cross-validation method. None means default (3-fold)\n",
    "#                        cv = 10, # positive intiger means k-fold (e.g. 10-fold)\n",
    "#                        #scoring  = 'neg_mean_squared_error', # MSE to calculate score\n",
    "#                        scoring  = 'r2', # MSE to calculate score\n",
    "#                        n_jobs=multiprocessing.cpu_count()) # Run on multiple cores\n",
    "    \n",
    "#     #clf = GridSearchCV(model_values[0], model_values[1], cv = 10, scoring  = 'r2')\n",
    "#     clf.fit(X_validate, Y_validate)\n",
    "#     name = model_values[2]\n",
    "#     final_results[name] = clf\n",
    "#     print (\"Hyperparameter results for {}\".format(name))\n",
    "#     print (\"\\tBest Score: {}\".format(clf.best_score_))\n",
    "#     print (\"\\tBest params: {}\".format(clf.best_params_))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

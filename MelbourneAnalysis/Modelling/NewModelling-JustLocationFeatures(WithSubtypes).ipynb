{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "<u>Tests using the following models :</u>\n",
    "* Linear regression\n",
    "* Random forest regressor\n",
    "* Ridge and Lasso Regularization (add on to linear modelling?)\n",
    "\n",
    "<u> Tests using the following variables:</u>\n",
    "* Sensor environment variables:\n",
    "    * Sensor_id\n",
    "    * Betweenness of the street \n",
    "    * Sub categories of buildings in proximity to the sensor:\n",
    "        * Average number of floors of buildings in vicinity\n",
    "        * Building type - Community use/Education/Entertainment/Events/Hospital or clinic/Office/Parking/Public display area/Residential/Retail/Storage/Transport/Unoccupied/Working\n",
    "    * Sub categories of landmarks in proximity to the sensor:   \n",
    "        * Landmark type - Community use/Health services/Leisure or recreation/Mixed use/Office/Place of Assembly/Place of Worship/Retail/ Transport\n",
    "    * Sub categories of furniture in proximity to the sensor:    \n",
    "        * Barbeque/Bicycle Rails/Bollard/Drinking fountaion/Crate or planter box/Hoop/Horse trough/Information pillar/Litter bin/Picnic setting/Seat/Tree guard\n",
    "    * Lights\n",
    "\n",
    "Normalise variables: should this be with MinMax or StandardScaler??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T08:09:42.167895Z",
     "start_time": "2020-05-20T08:09:36.778655Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, mean_squared_error,r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time as thetime\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from Functions import *\n",
    "\n",
    "# To display tables in HTML output\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "from Functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in formatted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"formatted_data_for_modelling.csv\", index_col = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get rid of columns that seem obviously irrelevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['Pressure', 'Humidity'],axis=1) # lights?\n",
    "# Remove the columns based on hours (as these are replaced by the categorical ones)\n",
    "data = data[data.columns.drop(list(data.filter(regex='h_')))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keep only sensors with relatively complete data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Filter to include just sensors which we know have quite complete data \n",
    "data = data[data['sensor_id'].isin([2,6,9,10,14,18])]\n",
    "data.reset_index(inplace=True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_justlocationfeatures= data.filter(regex=(\"sensor_id|buildings_|furniture_|landmarks_|avg_n_floors|hourly_counts|lights|betweenness\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in df_justlocationfeatures.columns:\n",
    "#     print(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for modelling - split into predictor/predictand variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Yfull' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2074/3778349796.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYfull\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Yfull' is not defined"
     ]
    }
   ],
   "source": [
    "np.unique(Yfull, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The predictor variables\n",
    "Xfull = df_justlocationfeatures.drop(['hourly_counts'], axis =1)\n",
    "\n",
    "# The variable to be predicted\n",
    "Yfull = df_justlocationfeatures['hourly_counts'].values\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(Xfull, Yfull, test_size=0.6666, random_state=123)\n",
    "\n",
    "#### Standardize both training and testing data\n",
    "scaler = StandardScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "# \n",
    "feature_list = list(Xfull.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling - Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Fit model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "### Print results\n",
    "print('Training score: ', model.score(X_train, Y_train))\n",
    "print('Test score: ', model.score(X_test, Y_test))\n",
    "print('CV score: ', (cross_val_score(model, X_train, Y_train)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the testing data\n",
    "predictions = model.predict(X_test)\n",
    "residuals = pd.DataFrame({'Predictions':predictions,'RealValues': Y_test})\n",
    "residuals['residuals'] = residuals.RealValues - residuals.Predictions\n",
    "\n",
    "# Not sure what this does\n",
    "(mean_squared_error(Y_test, predictions))**0.5\n",
    "\n",
    "# Collect the model coefficients in a dataframe\n",
    "df_coef = pd.DataFrame(model.coef_, index=X_train.columns,\n",
    "                       columns=['coefficients'])\n",
    "# calculate the absolute values of the coefficients to gauge influence (show importance of predictor variables)\n",
    "df_coef['coef_abs'] = df_coef.coefficients.abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance= df_coef.sort_values(by = 'coefficients', ascending = False)\n",
    "feature_importance.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2, constrained_layout=True, figsize = (10,5))\n",
    "\n",
    "axs[0].barh(feature_importance['index'][:10], feature_importance['coefficients'][:10])\n",
    "axs[0].invert_yaxis()\n",
    "plt.rcParams.update({'font.size': 5})\n",
    "axs[0].set_title(\"Feature Importance\", fontsize=15, y=1.01)\n",
    "axs[0].set_xlabel('Importance', fontsize = 12)\n",
    "axs[0].set_ylabel('Feature', fontsize = 12)\n",
    "axs[0].xaxis.set_tick_params(labelsize='xx-large')\n",
    "axs[0].yaxis.set_tick_params(labelsize='xx-large')\n",
    "\n",
    "axs[1].scatter(residuals.Predictions, Y_test, s=30, c='r', marker='+', zorder=10)\n",
    "axs[1].plot([Y_test.min(), Y_test.max()], [Y_test.min(), Y_test.max()], c='k', lw=2)\n",
    "axs[1].set_xlabel(\"Predicted Values\", size=10)\n",
    "axs[1].set_ylabel(\"Actual Values\", size=10)\n",
    "axs[1].xaxis.set_tick_params(labelsize='xx-large')\n",
    "axs[1].yaxis.set_tick_params(labelsize='xx-large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling - Random forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(Xfull, Yfull, test_size=0.6666, random_state=123)\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, Y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(X_test)\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - Y_test)\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmin(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors / Y_test)\n",
    "# # Calculate and display accuracy\n",
    "# accuracy = 100 - np.mean(mape)\n",
    "# print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull out one tree from the forest\n",
    "tree = rf.estimators_[5]\n",
    "# Export the image to a dot file\n",
    "export_graphviz(tree, out_file = 'tree.dot', feature_names = feature_list, rounded = True, precision = 1)\n",
    "# Use dot file to create a graph\n",
    "(graph, ) = pydot.graph_from_dot_file('tree.dot')\n",
    "# Write graph to a png file\n",
    "graph.write_png('tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit depth of tree to 3 levels\n",
    "rf_small = RandomForestRegressor(n_estimators=10, max_depth = 3)\n",
    "rf_small.fit(X_train, Y_train)\n",
    "# Extract the small tree\n",
    "tree_small = rf_small.estimators_[5]\n",
    "# Save the tree as a png image\n",
    "export_graphviz(tree_small, out_file = 'small_tree.dot', feature_names = feature_list, rounded = True, precision = 1)\n",
    "(graph, ) = pydot.graph_from_dot_file('small_tree.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame({'feature': feature_list,'importance':importances})      \n",
    "feature_importances= feature_importances.sort_values(by = 'importance', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2, constrained_layout=True, figsize = (10,5))\n",
    "\n",
    "axs[0].barh(feature_importances['feature'][:10], feature_importances['importance'][:10])\n",
    "axs[0].invert_yaxis()\n",
    "plt.rcParams.update({'font.size': 5})\n",
    "axs[0].set_title(\"Feature Importance\", fontsize=15, y=1.01)\n",
    "axs[0].set_xlabel('Importance', fontsize = 12)\n",
    "axs[0].set_ylabel('Feature', fontsize = 12)\n",
    "axs[0].xaxis.set_tick_params(labelsize='xx-large')\n",
    "axs[0].yaxis.set_tick_params(labelsize='xx-large')\n",
    "\n",
    "axs[1].scatter(predictions, Y_test, s=30, c='r', marker='+', zorder=10)\n",
    "axs[1].plot([Y_test.min(), Y_test.max()], [Y_test.min(), Y_test.max()], c='k', lw=2)\n",
    "axs[1].set_xlabel(\"Predicted Values\", size=10)\n",
    "axs[1].set_ylabel(\"Actual Values\", size=10)\n",
    "axs[1].xaxis.set_tick_params(labelsize='xx-large')\n",
    "axs[1].yaxis.set_tick_params(labelsize='xx-large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge and Lasso Regulariztion\n",
    "Regularization is implemented to avoid overfitting of data, especially when there is a large variance between training and test performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Ridge with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T21:37:18.331831Z",
     "start_time": "2020-05-16T21:25:18.125054Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "parameters = {'alpha': list(range(10)), 'fit_intercept': [True, False], \n",
    "              'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']}\n",
    "\n",
    "# define the model/ estimator\n",
    "model = Ridge(max_iter = 100000, normalisation = True)\n",
    "\n",
    "# define the grid search\n",
    "ridge= GridSearchCV(model, parameters,cv=5)\n",
    "\n",
    "#fit the grid search\n",
    "ridge.fit(X_train,Y_train)\n",
    "\n",
    "# best estimator\n",
    "print(ridge.best_estimator_)\n",
    "\n",
    "# best model\n",
    "best_model = ridge.best_estimator_\n",
    "best_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T21:37:30.465914Z",
     "start_time": "2020-05-16T21:37:18.420384Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print('Training score: ', best_model.score(X_train, Y_train))\n",
    "print('Test score: ', best_model.score(X_test, Y_test))\n",
    "print('CV score: ', (cross_val_score(best_model, X_train, Y_train)).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Lasso with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T22:05:05.733823Z",
     "start_time": "2020-05-16T21:37:54.456617Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "parameters = {'alpha': np.logspace(-4, 4, 10), 'fit_intercept': [True, False]}\n",
    "\n",
    "# define the model/ estimator\n",
    "model = Lasso(max_iter = 100000)\n",
    "\n",
    "# define the grid search\n",
    "lasso= GridSearchCV(model, parameters,cv=5)\n",
    "\n",
    "#fit the grid search\n",
    "lasso.fit(X_train,y_train)\n",
    "\n",
    "# best estimator\n",
    "print(lasso.best_estimator_)\n",
    "\n",
    "# best model\n",
    "best_model = lasso.best_estimator_\n",
    "best_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T22:09:18.554027Z",
     "start_time": "2020-05-16T22:05:05.739042Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print('Training score: ', best_model.score(X_train, y_train))\n",
    "print('Test score: ', best_model.score(X_test, y_test))\n",
    "print('CV score: ', (cross_val_score(best_model, X_train, y_train)).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T21:37:18.349292Z",
     "start_time": "2020-05-16T21:37:18.339922Z"
    },
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Decision Tree Regressor with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T13:48:10.991689Z",
     "start_time": "2020-05-19T13:14:00.703146Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dtr_params = {\n",
    "    'max_depth': list(range(1, 11))+[None],\n",
    "    'max_features': [None, 1, 2, 3],\n",
    "    'min_samples_split': [2, 3, 4, 5, 10, 15, 20, 25, 30, 40, 50],\n",
    "    'ccp_alpha': [0, 0.001, 0.005, 0.009, 0.01, 0.05]\n",
    "}\n",
    "\n",
    "\n",
    "# set the gridsearch\n",
    "model = DecisionTreeRegressor()\n",
    "dtr_gs = GridSearchCV(model, dtr_params, cv=5, verbose=1, n_jobs=2)\n",
    "dtr_gs.fit(X_train, y_train)\n",
    "print(dtr_gs.best_params_)\n",
    "best_model = dtr_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T13:48:16.960975Z",
     "start_time": "2020-05-19T13:48:14.395367Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print('Training score: ', best_model.score(X_train, y_train))\n",
    "print('Test score: ', best_model.score(X_test, y_test))\n",
    "print('CV score: ', (cross_val_score(best_model, X_train, y_train)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T21:06:04.926280Z",
     "start_time": "2020-05-19T21:06:04.709971Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.concat([all_sen_2012, all_sen_2013, all_sen_2014, all_sen_2015, all_sen_2016], axis = 0, sort = True)\n",
    "test = pd.concat([all_sen_2018, all_sen_2017], axis = 0, sort = True)\n",
    "\n",
    "X_train = train.copy()\n",
    "y_train = X_train.pop('daily_avg_counts')\n",
    "\n",
    "X_test = test.copy()\n",
    "y_test = X_test.pop('daily_avg_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T21:06:07.353324Z",
     "start_time": "2020-05-19T21:06:07.202317Z"
    }
   },
   "outputs": [],
   "source": [
    "#standardize\n",
    "scaler = StandardScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T23:13:34.810166Z",
     "start_time": "2020-05-19T23:10:00.283724Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dtr_params = {\n",
    "    'max_depth': [5, 10, 15, 20,50],\n",
    "    'max_features': [10, 50, None],\n",
    "    'min_samples_split': [10, 20, 40, 50, 70],\n",
    "    'ccp_alpha': [0.001, 0.005, 0.01, 0.1]}\n",
    "\n",
    "# set the gridsearch\n",
    "model = DecisionTreeRegressor()\n",
    "\n",
    "dtr_gs = GridSearchCV(model, dtr_params, cv=5, verbose=1, n_jobs=2)\n",
    "dtr_gs.fit(X_train, Y_train)\n",
    "print(dtr_gs.best_params_)\n",
    "best_model = dtr_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T23:13:36.084924Z",
     "start_time": "2020-05-19T23:13:34.814117Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print('Training score: ', best_model.score(X_train, y_train))\n",
    "print('Test score: ', best_model.score(X_test, y_test))\n",
    "print('CV score: ', (cross_val_score(best_model, X_train, y_train)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "predictions = best_model.predict(X_test)\n",
    "residuals = pd.DataFrame(predictions, y_test)\n",
    "residuals.reset_index(inplace = True)\n",
    "residuals.rename({'daily_avg_counts': 'y_test', 0: 'predictions'}, axis = 1, inplace = True)\n",
    "residuals['residuals'] = residuals.y_test - residuals.predictions\n",
    "residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = residuals[['y_test', 'predictions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mean_squared_error(y_test, predictions))**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame(list(zip(X_train.columns,best_model.feature_importances_))).sort_values(by=1,ascending=True)\n",
    "feature_importance.rename({1: 'Feature Importance', 0: 'Feature'}, axis = 1, inplace = True)\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train['sensor_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('ticks')\n",
    "sns.set(font_scale = 2)\n",
    "fig, ax = plt.subplots()\n",
    "# the size of A4 paper\n",
    "fig.set_size_inches(16, 12)\n",
    "sns.barplot(x='Feature Importance', y='Feature', data=feature_importance[-15:], orient='h', palette = 'rocket', saturation=0.7)  \n",
    "ax.set_title(\"Feature Importance\", fontsize=40, y=1.01)\n",
    "ax.set_xlabel('Importance', fontsize = 30)\n",
    "ax.set_ylabel('Feature', fontsize = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.axes_style(style='white')\n",
    "sns.set(font_scale = 2)\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(16, 12)\n",
    "ax = sns.regplot(x=\"predictions\", y=\"y_test\", data= predictions,  scatter_kws = {'color': 'lightsalmon'}, \n",
    "                 line_kws = {'color': 'darksalmon'})\n",
    "ax.set_xlabel('Predicted', fontsize = 30)\n",
    "ax.set_ylabel('Actual', fontsize = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the best model  \n",
    "Use k-fold cross validation to evaluate a range of regression algorithms on the training data. Use a pipeline for evaluation which first scales the (weather) data. Print the results and assess which models perform best.\n",
    "\n",
    "The following models were trialled:\n",
    "\n",
    "* Decision Tree\n",
    "* Random Forest\n",
    "* Extra Trees\n",
    "* Dummy Regressor\n",
    "* Elastic Net CV\n",
    "* Passive Aggressive\n",
    "* RANSAC\n",
    "* SGD\n",
    "* TheilSen (dropped in code below because it takes too long)\n",
    "* K Neighbours\n",
    "* LinearRegression\n",
    "* XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a list of all the models to use\n",
    "# Models = {'LinearRegression': LinearRegression,'DecisionTree' : DecisionTreeRegressor,\n",
    "#           'RandomForest': RandomForestRegressor, 'ExtraTrees' : ExtraTreesRegressor,\n",
    "#           'DummyRegressor' :DummyRegressor, 'ElasticNetCV' : ElasticNetCV, \n",
    "#           'PassiveAggressive' : PassiveAggressiveRegressor, #RANSAC': RANSACRegressor, # This one is terrible too\n",
    "#           'SGD': SGDRegressor, #'TheilSen': TheilSenRegressor, # Drop this - it isn't great and takes too long\n",
    "#           'KN': KNeighborsRegressor}#, 'XGBoost': xgb.XGBRegressor}\n",
    " \n",
    "# # Now just run each model, but do this in multiple processes simultaneously to save time    \n",
    "# # Now call that function simultaneously for each model\n",
    "# p = Pool(processes=None) # A pool of processes (one for each core)\n",
    "# results = p.map(run_model, [(name, model_type) for name, model_type in Models.items()])\n",
    "\n",
    "# # Sort the results by median mse (that's item 5 in the tuple)\n",
    "# results.sort(key=lambda x: x[5], reverse=True)\n",
    "\n",
    "# # Put the results in a nice dictionary and print them\n",
    "# results_dict = {}\n",
    "# txt = \"<table><thead><td>Name</td><td>Median R2</td><td>Median MSE</td><td>runtime (sec)</td></thead>\"\n",
    "# for name, model, all_r2, r2, all_mse, mse, runtime in results:\n",
    "#     txt += \"<tr><td>{}</td><td>{}</td><td>{}</td><td>{}</td></tr>\".format(name, r2, mse, runtime)\n",
    "#     results_dict[name] = (model, all_r2, r2, all_mse, mse, runtime)\n",
    "# txt += \"</table>\"\n",
    "# display(HTML(txt)) # print as html\n",
    "\n",
    "# min_mse = min([mse for (name, model, all_r2, r2, all_mse, mse, runtime) in results])\n",
    "               \n",
    "# x =  [ name for (name, model, all_r2, r2, all_mse, mse, runtime) in results]\n",
    "# y1 = [ mse-min_mse   for (name, model, all_r2, r2, all_mse, mse, runtime) in results]\n",
    "# y2 = [ r2 if r2 > 0 else 0 for (name, model, all_r2, r2, all_mse, mse, runtime) in results]\n",
    "\n",
    "# fig, (ax1,ax2) = plt.subplots(1, 2, figsize=(15, 7))\n",
    "\n",
    "# ax1.set_title(\"MSE\")\n",
    "# #ax1.invert_yaxis()\n",
    "# ax1.bar(range(len(x)), y1)\n",
    "# ax1.set_xticks(range(len(x)))\n",
    "# ax1.set_xticklabels(x, rotation=90)\n",
    "# ax1.set_ylim([27000000000, 29000000000])\n",
    "\n",
    "# ax2.set_title(\"R^2\")\n",
    "# ax2.bar(range(len(x)), y2)\n",
    "# ax2.set_xticks(range(len(x)))\n",
    "# ax2.set_xticklabels(x, rotation=90)\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# #del x,y1, y2\n",
    "\n",
    "# ## Set up a dictionary containing the hyperparameters we want to tune\n",
    "# hyperparameters_rf = { 'randomforestregressor__max_features' : ['auto', 'sqrt', 'log2'],\n",
    "#                   'randomforestregressor__max_depth': [None, 5, 3, 1]}\n",
    "# # hyperparameters_xgb = {'xgbregressor__max_depth': range(1, 11, 2),\n",
    "# #                    'xgbregressor__n_estimators' : range(50, 400, 50),\n",
    "# #                    'xgbregressor__learning_rate' : [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]}\n",
    "# hyperparameters_lr = {}\n",
    "\n",
    "# # Set up the pipeline containing the scalers\n",
    "# pipeline_rf = make_pipeline(MinMaxScaler(feature_range = (0,1)), \n",
    "#                          RandomForestRegressor(n_estimators=100))\n",
    "# # pipeline_xgb = make_pipeline(MinMaxScaler(feature_range = (0,1)),\n",
    "# #                          xgb.XGBRegressor(n_estimators=100))\n",
    "# pipeline_lr = make_pipeline(MinMaxScaler(feature_range = (0,1)),\n",
    "#                          LinearRegression())\n",
    "\n",
    "# # Store the scores in a results dictionary (and print them)\n",
    "# final_results = {}\n",
    "# for model_values in [(pipeline_rf,  hyperparameters_rf,  'RandomForest'),\n",
    "# #                      (pipeline_xgb, hyperparameters_xgb, 'XGBoost'),\n",
    "#                      (pipeline_lr,  hyperparameters_lr,  'LinearRegression')]:\n",
    "    \n",
    "#     clf = GridSearchCV(model_values[0], model_values[1], \n",
    "#                        #cv = None, # Cross-validation method. None means default (3-fold)\n",
    "#                        cv = 10, # positive intiger means k-fold (e.g. 10-fold)\n",
    "#                        #scoring  = 'neg_mean_squared_error', # MSE to calculate score\n",
    "#                        scoring  = 'r2', # MSE to calculate score\n",
    "#                        n_jobs=multiprocessing.cpu_count()) # Run on multiple cores\n",
    "    \n",
    "#     #clf = GridSearchCV(model_values[0], model_values[1], cv = 10, scoring  = 'r2')\n",
    "#     clf.fit(X_validate, Y_validate)\n",
    "#     name = model_values[2]\n",
    "#     final_results[name] = clf\n",
    "#     print (\"Hyperparameter results for {}\".format(name))\n",
    "#     print (\"\\tBest Score: {}\".format(clf.best_score_))\n",
    "#     print (\"\\tBest params: {}\".format(clf.best_params_))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

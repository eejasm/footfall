{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "<u>Tests using the following models :</u>\n",
    "* Linear regression\n",
    "* Random forest regressor\n",
    "* Ridge and Lasso Regularization (add on to linear modelling?)\n",
    "\n",
    "<u> Tests using the following variables:</u>\n",
    "* Weather variables (rain, temperature, windspeed)\n",
    "* Time variables (Day of week, month, year, time of day, public holiday)\n",
    "* Sensor environment variables:\n",
    "    * Sensor_id\n",
    "    * Betweenness of the street \n",
    "    * Buildings in proximity to the sensor\n",
    "    * Landmarks in proximity to the sensor  \n",
    "    * Furniture in proximity to the sensor    \n",
    "    * Lights in proximity to the sensor   \n",
    "\n",
    "\n",
    "Normalise variables: should this be with MinMax or StandardScaler??\n",
    "\n",
    "\n",
    "Process:\n",
    "* Keep only data from sensor's with relatively complete data\n",
    "* Split data into training ( 75%) and test (25%)\n",
    "* Define the models to use in testing (linear regression, random forest, xgboost)\n",
    "* Define the error metrics to use in evaluating the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import copy\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "# from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, cross_validate, cross_val_predict\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import classification_report, mean_squared_error,r2_score, accuracy_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# import time as thetime\n",
    "# from xgboost import XGBClassifier, XGBRegressor\n",
    "# from time import time\n",
    "# from sklearn.inspection import permutation_importance\n",
    "# from scipy import stats\n",
    "# import math\n",
    "# from eli5.sklearn import PermutationImportance\n",
    "\n",
    "# from warnings import simplefilter\n",
    "# simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# import multiprocessing\n",
    "\n",
    "# # To display tables in HTML output\n",
    "# from IPython.display import HTML, display\n",
    "\n",
    "from Functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in formatted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../Cleaned_data/formatted_data_for_modelling_allsensors.csv\", index_col = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete unneeded columns\n",
    "We currently include data from all sensors (even incomplete ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['sensor_id'],axis=1) # don't want this included\n",
    "# Get rid of columns in which none of the sensors have a value\n",
    "for column in data.columns:\n",
    "    if np.nanmax(data[column]) ==0:\n",
    "        del data[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter columns using the regex pattern in function input\n",
    "regex_pattern = 'buildings$|furniture$|landmarks$'\n",
    "data = data[data.columns.drop(list(data.filter(regex=regex_pattern)))].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a random variable (to compare performance of other variables against)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(seed=42)\n",
    "data['random'] = np.random.random(size=len(data))\n",
    "data[\"random_cat\"] = rng.randint(3, size=data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for modelling \n",
    "### Split into predictor/predictand variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The predictor variables\n",
    "Xfull = data.drop(['hourly_counts'], axis =1)\n",
    "# The variable to be predicted\n",
    "Yfull = data['hourly_counts'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the (non Sin/Cos) time columns and then remove them\n",
    "Need them later to segment the results by hour of the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_time_columns = Xfull[['day_of_month_num', 'time', 'weekday_num', 'time_of_day']]\n",
    "Xfull = Xfull.drop(['day_of_month_num', 'time', 'weekday_num', 'time_of_day','year', 'month','day', 'datetime', 'month_num'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model pipelines (linear regression, random forest and XGBoost)\n",
    "Include process to scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model_pipeline = Pipeline(steps=[['scaler',StandardScaler()],['linear_regressor',LinearRegression()]])\n",
    "rf_model_pipeline = Pipeline(steps=[['scaler',StandardScaler()],['rf_regressor', RandomForestRegressor(n_estimators = 10,random_state = 1, n_jobs = 32)]])\n",
    "# xgb_model_pipeline = Pipeline(steps=[['scaler',StandardScaler()],['xgb_regressor',XGBRegressor(random_state=1, n_jobs = 200)]])\n",
    "# et_model_pipeline = Pipeline(steps=[['scaler',StandardScaler()],['et_regressor',ExtraTreesRegressor (n_estimators = 500, random_state = 1, n_jobs = 32)]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run models with cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the error metrics for the cross-validation to return, and the parameters of the cross validatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_metrics = ['neg_mean_absolute_error', 'r2', 'neg_root_mean_squared_error']\n",
    "cv_parameters = KFold(n_splits=10, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define regex's to remove columns not needed in various splits of removing column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_regex_dict = {'withsubtypes':'buildings$|furniture$|landmarks$'}\n",
    "# #                      'nosubtyes':'buildings_|furniture_|landmarks_|sensor_id'}\n",
    "# #                      'time_and_weather':'buildings|furniture|landmarks|h_|lights|avg_n_floors|betweenness',\n",
    "# #                       'just_location_features':'buildings$|furniture$|landmarks$|school_holiday|public_holiday|Temp|Humidity|Pressure|Rain|WindSpeed|Sin|Cos'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through each combination of the models, and the variables to include in the modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running rf_regressor model, variables include withsubtypes\n"
     ]
    }
   ],
   "source": [
    "# Dataframe to store the scores for each model\n",
    "error_metric_scores = pd.DataFrame()\n",
    "\n",
    "# Dictionary to store dataframes of feature importance scores\n",
    "feature_importance_scores ={}\n",
    "\n",
    "# models_dict = {\"linear_regressor\": lr_model_pipeline, \"xgb_regressor\":xgb_model_pipeline, \n",
    "#                \"rf_regressor\":rf_model_pipeline, \"et_regressor\":et_model_pipeline}\n",
    "models_dict = {\"rf_regressor\":rf_model_pipeline}\n",
    "for model_name,model in models_dict.items():\n",
    "    for regex_name, regex in column_regex_dict.items():\n",
    "        # Run the model: return the estimators and a dataframe containing evaluation metrics\n",
    "        estimators, error_metrics_df, feature_list, predictions = run_model_with_cv_and_predict(\n",
    "            model, model_name, error_metrics, cv_parameters, Xfull, Yfull, regex_name, regex) \n",
    "        # Add evaluation metric scores for this model to the dataframe containing the metrics for each model\n",
    "        error_metric_scores = error_metric_scores.append(error_metrics_df)\n",
    "        \n",
    "        # Create dataframe of feature importances (no feature importances for linear regression)\n",
    "        if model_name != 'linear_regressor':\n",
    "            feature_importances = pd.DataFrame(index =[feature_list])\n",
    "            for idx,estimator in enumerate(estimators):\n",
    "                    feature_importances['Estimator{}'.format(idx)] = estimators[idx][model_name].feature_importances_\n",
    "            feature_importance_scores[\"{}_{}\".format(model_name, regex_name)] = feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the predicted vs actual values from the CV process\n",
    "Within cross validation each data point is included in the test set only once and thus despite their beng multiple cross-validation folds, each true value of Y has only one associated prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# using_datashader(ax, Yfull, predictions, 'log')\n",
    "# ax.plot([Yfull.min(), Yfull.max()], [Yfull.min(), Yfull.max()], c='k', lw=0.5)\n",
    "# ax.set_ylabel(\"Predicted Values\", size=10)\n",
    "# ax.set_xlabel(\"Actual Values\", size=10)\n",
    "# ax.xaxis.set_tick_params(labelsize='xx-large')\n",
    "# ax.yaxis.set_tick_params(labelsize='xx-large')\n",
    "# ax.set_xlim([0, 2000])\n",
    "# ax.set_ylim([0, 2000]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the accuracy scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error_metric_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importances from within cross-validation\n",
    "If reporting feature importances from the model, then would use those from fitting the final model on the full dataset. However, this is useful as a measure of the stability of the feature importances that the model reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_df = feature_importance_scores[\"rf_regressor_withsubtypes\"].copy()\n",
    "feature_importances_df.reset_index(inplace=True)\n",
    "feature_importances_df.rename(columns={'level_0':'Variable'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the most important top 10 columns for each estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important_columns=pd.DataFrame()\n",
    "# for column in feature_importances_df.columns[1:]:\n",
    "#     this_col = feature_importances_df[['Variable', column]]\n",
    "#     important_columns[column] = this_col.sort_values(column, ascending = False)['Variable'].tolist()[0:10]\n",
    "# important_columns    "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

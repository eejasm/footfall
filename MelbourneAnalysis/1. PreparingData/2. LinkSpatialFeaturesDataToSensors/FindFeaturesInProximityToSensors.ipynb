{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find features in proximity to sensors\n",
    "\n",
    "NB: Needs to be run with footfall_spatial environment\n",
    "\n",
    "Within a radius of each sensor, find:\n",
    "* the number of features of each type (bike stations, lights, landmarks, furniture, and buildings for each year)\n",
    "* the number of features of each subtype for landmarks, furniture and buildings  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T14:51:19.467890Z",
     "start_time": "2020-05-20T14:51:17.926847Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from IPython.display import Image\n",
    "from shapely.geometry import Point, Polygon\n",
    "import folium\n",
    "import numpy as np\n",
    "from shapely.ops import transform\n",
    "import pyproj\n",
    "import os\n",
    "import contextily as cx\n",
    "from shapely.geometry import Point, LineString\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from shapely.errors import ShapelyDeprecationWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=ShapelyDeprecationWarning) \n",
    "\n",
    "buffer_size_m = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T14:51:25.829644Z",
     "start_time": "2020-05-20T14:51:25.823261Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_features_gdf (fp):\n",
    "    # Read in csv\n",
    "    feature_df = pd.read_csv(fp)\n",
    "    # Convert to geodataframe\n",
    "    feature_gdf = gpd.GeoDataFrame(feature_df, geometry=gpd.points_from_xy(feature_df['Longitude'], feature_df['Latitude']))\n",
    "    feature_gdf.set_crs(epsg=4326, inplace=True)\n",
    "    return feature_gdf\n",
    "\n",
    "def draw_buffers(sensors_gdf, buffer_size_m):\n",
    "    # Convert CRS of sensor data to one that works with finding the radius\n",
    "    reprojected_sensors = sensors_gdf.copy()\n",
    "    reprojected_sensors.to_crs(crs=3577, inplace = True)\n",
    "\n",
    "    # Draw a buffer around each sensor in metres\n",
    "    reprojected_sensors['polygon'] = reprojected_sensors.geometry.buffer(buffer_size_m)   \n",
    "\n",
    "    return reprojected_sensors\n",
    "\n",
    "# Function which finds which features from a geodataframe of features are within the radius of a sensor\n",
    "# and saves the location and feature sub-types of these\n",
    "def find_features_near_sensor (sensor_num, gdf, buffer_size_m, grouping_col_name):\n",
    "    # Convert CRS of sensor data to one that works with finding the radius\n",
    "    global buffered_sensors\n",
    "\n",
    "    # Get geodataframe from just this sensor\n",
    "    this_sensor_gdf = buffered_sensors[buffered_sensors.sensor_id == sensor_num]\n",
    "    this_sensor_gdf.reset_index(inplace = True, drop = True)\n",
    "\n",
    "    # Set up reprojection\n",
    "    project = pyproj.Transformer.from_crs(pyproj.CRS('EPSG:4326'), pyproj.CRS('EPSG:3577'), always_xy=True).transform\n",
    "\n",
    "    # Check if each of the features is within the radius of this sensor\n",
    "    # Save the locations and themes of these features into two lists\n",
    "    locations_in_radius = []\n",
    "    themes_in_radius = []\n",
    "    n_rows = []\n",
    "    for feature in gdf.iterrows():\n",
    "        transformed_point = transform(project, feature[1].geometry)\n",
    "        if this_sensor_gdf['polygon'][0].contains(transformed_point):\n",
    "            locations_in_radius.append(feature[1].geometry)\n",
    "            themes_in_radius.append(feature[1][grouping_col_name])\n",
    "            if grouping_col_name == 'building_use':\n",
    "                n_rows.append(feature[1].n_floors)\n",
    "                \n",
    "    # Populate nrows for the features which arent buildings\n",
    "    if len(n_rows) ==0:\n",
    "        n_rows = [np.nan] * len(locations_in_radius)\n",
    "    \n",
    "    return locations_in_radius, themes_in_radius, n_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Read in data**\n",
    "## <ins>Sensors</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T14:51:30.725848Z",
     "start_time": "2020-05-20T14:51:30.706229Z"
    }
   },
   "outputs": [],
   "source": [
    "sensors_gdf =create_features_gdf('../../Data/FootfallData/melbourne_locations.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Draw a circle around each sensor, within which to look for features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffered_sensors = draw_buffers(sensors_gdf, buffer_size_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T14:51:34.570519Z",
     "start_time": "2020-05-20T14:51:34.497761Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filter out just the columns we want\n",
    "sensors_gdf = sensors_gdf[['sensor_id', 'Latitude', 'Longitude', 'geometry']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <ins>Feature data</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T14:51:37.498686Z",
     "start_time": "2020-05-20T14:51:37.355876Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gdfs={}\n",
    "for feature in [\"lights\",\"street_inf\",\"bikes\",\"landmarks\",\"memorials\",\"trees\",\"transport_stops\",\n",
    "                \"bus-stops\",\"tram-stops\", \"metro-stations\", 'taxi-ranks',  \"big-car-parks\"]:\n",
    "    features_gdf = create_features_gdf('../../Cleaned_data/SpatialFeatures/{}_clean.csv'.format(feature))\n",
    "    gdfs[feature]=features_gdf\n",
    "    \n",
    "gdf_subtheme_column_name = [\"lamp_rating_w\",\"feature\", \"capacity\", \"theme\", \"Description\", \n",
    "                            \"Common Name\", \"Type\", \"Type\", \"Type\", \"Type\", \"num_spaces\", 'Type']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key = \"street_inf\"\n",
    "# count =1\n",
    "# print(key)\n",
    "# # Find the features from this geodataframe in the radius of this sensor\n",
    "# features_this_sensor = find_features_near_sensor(sensor_num, gdfs[key], buffer_size_m, gdf_subtheme_column_name[count])\n",
    "\n",
    "# # Create dataframe with the location and type of feature for this geodataframe nr the sensor\n",
    "# features_df_this_gdf= pd.DataFrame({'Location': features_this_sensor[0], 'Type': key, \n",
    "#                                          'Subtype': features_this_sensor[1],\n",
    "#                                    'N_floors': features_this_sensor[2]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find number of each feature within the radius of each sensor\n",
    "\n",
    "NB: If you use the full buildings_gdf with this method then it returns way too many buildings as each building is listed seperately in each year  \n",
    "Can check this with:  \n",
    "buildings_gdf[buildings_gdf.duplicated(['Longitude', 'Latitude'], keep=False)].sort_values(['Longitude', 'Latitude'])[0:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_to_save_to =  \"../../Cleaned_data/FeaturesNearSensors/num_features_near_sensors_{}.csv\".format(buffer_size_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings_gdf = create_features_gdf('../../Cleaned_data/SpatialFeatures/buildings_clean.csv')\n",
    "# Add a gdf containing just the buildings present in each year to the dictionary of gdfs\n",
    "for year in sorted(buildings_gdf.year.unique()):\n",
    "    this_year = buildings_gdf[buildings_gdf.year == year].copy()\n",
    "    this_year.reset_index(inplace=True, drop = True)\n",
    "    gdfs[\"buildings_{}\".format(year)] = this_year  \n",
    "\n",
    "# Create a list of the sub column names for each GDF\n",
    "for year in buildings_gdf.year.unique():\n",
    "    gdf_subtheme_column_name.append('building_use')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For counting the number of features:\n",
    "# Keys will be sensor numbers, items will be list of number of each type of feature in this sensor's radius\n",
    "num_features = {}\n",
    "# Keys will be sensor numbers, items will be a dataframe containing location and type of features in sensor radius\n",
    "feature_details = {}\n",
    "# Dataframe to store the average number of floors in the buildings present in each year, in radius of each sensor\n",
    "building_floors_df = pd.DataFrame()\n",
    "\n",
    "# Loop through each sensor\n",
    "for sensor_num in sorted(sensors_gdf['sensor_id'].unique().tolist()):\n",
    "    # Dataframe to contain location and feature types from all gdfs, for this sensor \n",
    "    features_df_this_sensor = pd.DataFrame(None)\n",
    "    # Lists to store the data for each sensor\n",
    "    n_features_this_sensor = []\n",
    "    buildings_avg_n_floors_this_sensor = []\n",
    "    building_years = []\n",
    "\n",
    "    # loop through each geodataframe\n",
    "    for count, key in enumerate(gdfs.keys()):\n",
    "        # Find the features from this geodataframe in the radius of this sensor\n",
    "        features_this_sensor = find_features_near_sensor(sensor_num, gdfs[key], buffer_size_m, gdf_subtheme_column_name[count])\n",
    "\n",
    "        # Create dataframe with the location and type of feature for this geodataframe nr the sensor\n",
    "        features_df_this_gdf= pd.DataFrame({'Location': features_this_sensor[0], 'Type': key, \n",
    "                                                 'Subtype': features_this_sensor[1],\n",
    "                                           'N_floors': features_this_sensor[2]})\n",
    "        \n",
    "        # If we are looking at building data, then find the avg number of floors for this year of building data\n",
    "        # Add to the list of values\n",
    "        if 'buildings' in key:\n",
    "            buildings_avg_n_floors_this_sensor.append(features_df_this_gdf['N_floors'].mean())\n",
    "            building_years.append(key.split('_')[1])\n",
    "\n",
    "        # Add to dataframe containing results from all geodataframes\n",
    "        features_df_this_sensor = pd.concat([features_df_this_sensor,features_df_this_gdf],axis=0)\n",
    "\n",
    "        # Add the number of features of this type to the list\n",
    "        n_features_this_sensor.append(len(features_df_this_gdf))\n",
    "\n",
    "    # Add number/feature details to dictionaries\n",
    "    num_features[sensor_num] = n_features_this_sensor\n",
    "    feature_details[sensor_num] = features_df_this_sensor\n",
    "    building_floors_df[\"{}\".format(sensor_num)] = buildings_avg_n_floors_this_sensor\n",
    "\n",
    "# Reformat\n",
    "num_features = pd.DataFrame(num_features).T\n",
    "num_features.columns =gdfs.keys()\n",
    "num_features.reset_index(inplace=True)\n",
    "\n",
    "# Add data on average number of floors for buildings in each year\n",
    "building_floors_df.index =  [\"avg_n_floors_{}\".format(item) for item in building_years]\n",
    "building_floors_df = building_floors_df.T\n",
    "building_floors_df.reset_index(inplace = True, drop=True)\n",
    "\n",
    "# Join datasets\n",
    "num_features = num_features.join(building_floors_df)\n",
    "num_features\n",
    "\n",
    "# # Add sensor Id as column\n",
    "# num_features['sensor_id'] = sorted(sensors_gdf['sensor_id'].unique().tolist())\n",
    "# # Save\n",
    "# # del num_features['index']\n",
    "# num_features.to_csv(fp_to_save_to, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the features within the radius for one sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sensor_num = 1\n",
    "# this_sensor = buffered_sensors[buffered_sensors['sensor_id'] ==sensor_num].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this_sensors_features = feature_details[sensor_num]\n",
    "# this_sensors_features['Longitude'] = this_sensors_features.Location.apply(lambda p: p.x)\n",
    "# this_sensors_features['Latitude'] = this_sensors_features.Location.apply(lambda p: p.y)\n",
    "# this_sensors_features.reset_index(inplace=True, drop = True)\n",
    "\n",
    "# # Plot\n",
    "# melbourne_map = folium.Map(location=[this_sensor.Latitude.mean(),\n",
    "#                            this_sensor.Longitude.mean()], zoom_start=18, control_scale=True)#, min_zoom = 13)\n",
    "# # Add sensor location marker\n",
    "# folium.Marker([this_sensor[\"Latitude\"], this_sensor[\"Longitude\"]], popup=this_sensor[\"sensor_id\"], \n",
    "#               icon = folium.Icon(color=\"red\")).add_to(melbourne_map)\n",
    "\n",
    "# # # Add buffer zone\n",
    "# folium.GeoJson(data=this_sensor[\"polygon\"]).add_to(melbourne_map)\n",
    "\n",
    "# # # Add features\n",
    "# for index in range(0, len(this_sensors_features)):\n",
    "#     feature = this_sensors_features[this_sensors_features.index ==index].copy()\n",
    "#     folium.CircleMarker([feature['Latitude'], feature['Longitude']], popup=feature[\"Type\"],\n",
    "#         color = 'black', fill_color = 'white', fill = 'True', fill_opacity = True).add_to(melbourne_map)\n",
    "       \n",
    "# melbourne_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Find number of subtypes of features in each sensor's radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe to contain location and feature types from all gdfs, for this sensor \n",
    "subtypes = pd.DataFrame(None)\n",
    "\n",
    "for sensor_num in sorted(sensors_gdf['sensor_id'].unique().tolist()):\n",
    "    this_sensors_features = feature_details[sensor_num]\n",
    "    \n",
    "    subtypes_this_sensor = pd.DataFrame(None)\n",
    "    \n",
    "    for key in [\"bikes\", \"street_inf\", \"landmarks\",\"buildings_2010\",'buildings_2011', \"buildings_2012\", \"buildings_2013\",\"buildings_2014\",\n",
    "                \"buildings_2015\", \"buildings_2016\",\"buildings_2017\",\"buildings_2018\", \"buildings_2019\", \"buildings_2020\"]:\n",
    "        if key in this_sensors_features['Type'].unique() : \n",
    "            feature = this_sensors_features[this_sensors_features['Type'] == key]\n",
    "            feature = feature.groupby('Subtype').agg({'Subtype': 'count'})\n",
    "            feature = feature.rename(columns={\"Subtype\":sensor_num})\n",
    "            feature.index = '{}_'.format(key) + feature.index.astype(str)\n",
    "            \n",
    "            subtypes_this_sensor = pd.concat([subtypes_this_sensor,feature],axis=0)\n",
    "     \n",
    "    # Add to dataframe containing results from all geodataframes\n",
    "    subtypes = pd.concat([subtypes,subtypes_this_sensor],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtypes = subtypes.T\n",
    "subtypes.reset_index(inplace = True)\n",
    "subtypes.rename(columns={'index':'sensor_id'}, inplace = True)\n",
    "subtypes = subtypes.rename_axis(None, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtypes.to_csv(\"../../Cleaned_data/FeaturesNearSensors/feature_subtypes_near_sensors_{}.csv\".format(buffer_size_m),  index = False)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

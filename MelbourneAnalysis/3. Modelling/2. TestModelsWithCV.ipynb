{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "<u>Tests using the following models :</u>\n",
    "* Linear regression\n",
    "* Random forest regressor\n",
    "* Ridge and Lasso Regularization (add on to linear modelling?)\n",
    "\n",
    "<u> Tests using the following variables:</u>\n",
    "* Weather variables (rain, temperature, windspeed)\n",
    "* Time variables (Day of week, month, year, time of day, public holiday)\n",
    "* Sensor environment variables:\n",
    "    * Sensor_id\n",
    "    * Betweenness of the street \n",
    "    * Buildings in proximity to the sensor\n",
    "    * Landmarks in proximity to the sensor  \n",
    "    * Furniture in proximity to the sensor    \n",
    "    * Lights in proximity to the sensor   \n",
    "\n",
    "\n",
    "Normalise variables: should this be with MinMax or StandardScaler??\n",
    "\n",
    "\n",
    "Process:\n",
    "* Keep only data from sensor's with relatively complete data\n",
    "* Split data into training ( 75%) and test (25%)\n",
    "* Define the models to use in testing (linear regression, random forest, xgboost)\n",
    "* Define the error metrics to use in evaluating the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor \n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import Pipeline\n",
    "import folium\n",
    "import branca.colormap as cm\n",
    "from eli5.sklearn import PermutationImportance\n",
    "import joblib\n",
    "import os\n",
    "import psutil\n",
    "\n",
    "from Functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size_m = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in formatted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../Cleaned_data/FormattedDataForModelling/formatted_data_for_modelling_allsensors_{}.csv\".format(buffer_size_m), index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete unneeded columns\n",
    "We currently include data from all sensors (even incomplete ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_ids = data['sensor_id']\n",
    "data = data.drop(['sensor_id'],axis=1) # don't want this included\n",
    "# Get rid of columns in which none of the sensors have a value\n",
    "for column in data.columns:\n",
    "    if np.nanmax(data[column]) ==0:\n",
    "        del data[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter columns using the regex pattern in function input\n",
    "regex_pattern = 'buildings$|furniture$|landmarks$'\n",
    "data = data[data.columns.drop(list(data.filter(regex=regex_pattern)))].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a random variable (to compare performance of other variables against)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(seed=42)\n",
    "data['random'] = np.random.random(size=len(data))\n",
    "data[\"random_cat\"] = rng.randint(3, size=data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for modelling \n",
    "### Split into predictor/predictand variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The predictor variables\n",
    "Xfull = data.drop(['hourly_counts'], axis =1)\n",
    "# The variable to be predicted\n",
    "Yfull = data['hourly_counts'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the (non Sin/Cos) time columns and then remove them\n",
    "Need them later to segment the results by hour of the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_time_columns = Xfull[['day_of_month_num', 'time', 'weekday_num', 'time_of_day']]\n",
    "Xfull = Xfull.drop(['day_of_month_num', 'time', 'weekday_num', 'time_of_day','year', 'month','day', 'datetime', 'month_num'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model pipelines (linear regression, random forest and XGBoost)\n",
    "Include process to scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model_pipeline = Pipeline(steps=[['scaler',StandardScaler()],['linear_regressor',LinearRegression()]])\n",
    "rf_model_pipeline = Pipeline(steps=[['scaler',StandardScaler()],['rf_regressor', RandomForestRegressor(random_state = 1, n_jobs = 10)]])\n",
    "xgb_model_pipeline = Pipeline(steps=[['scaler',StandardScaler()],['xgb_regressor',xgb.XGBRegressor(random_state=1, n_jobs = 16)]])\n",
    "et_model_pipeline = Pipeline(steps=[['scaler',StandardScaler()],['et_regressor',ExtraTreesRegressor (random_state = 1, n_jobs = 16)]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run models with cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the error metrics for the cross-validation to return, and the parameters of the cross validatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_metrics = ['neg_mean_absolute_error', 'r2', 'neg_root_mean_squared_error', 'neg_mean_absolute_percentage_error']\n",
    "cv_parameters = KFold(n_splits=10, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define regex's to remove columns not needed in various splits of removing column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_regex_dict = {'withsubtypes':'buildings$|furniture$|landmarks$'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through each combination of the models, and the variables to include in the modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_metric_scores = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = cross_validate(rf_model_pipeline, Xfull, Yfull, cv=cv_parameters, \n",
    "                              scoring=error_metrics ,return_estimator=True, error_score=\"raise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6193MB\n",
      "Running xgb_regressor model, variables include withsubtypes\n",
      "running cross_validate\n"
     ]
    }
   ],
   "source": [
    "# Dataframe to store the scores for each model\n",
    "error_metric_scores = pd.DataFrame()\n",
    "\n",
    "# Dictionary to store dataframes of feature importance scores\n",
    "predictions_df = pd.DataFrame()\n",
    "\n",
    "# Dictionary to store dataframes of feature importance scores\n",
    "feature_importance_scores ={}\n",
    "\n",
    "models_dict = {\"xgb_regressor\":xgb_model_pipeline}\n",
    "\n",
    "# models_dict = {\"rf_regressor\":rf_model_pipeline}\n",
    "for model_name,model in models_dict.items():\n",
    "    for regex_name, regex in column_regex_dict.items():\n",
    "        print_mem()\n",
    "        # Run the model: return the estimators and a dataframe containing evaluation metrics\n",
    "        estimators, error_metrics_df, feature_list, predictions = run_model_with_cv_and_predict(\n",
    "            model, model_name, error_metrics, cv_parameters, Xfull, Yfull, regex_name, regex) \n",
    "        # Add evaluation metric scores for this model to the dataframe containing the metrics for each model\n",
    "        error_metric_scores = error_metric_scores.append(error_metrics_df)\n",
    "        \n",
    "        predictions_df[model_name] =predictions\n",
    "        \n",
    "        # Create dataframe of feature importances (no feature importances for linear regression)\n",
    "        if model_name != 'linear_regressor':\n",
    "            feature_importances = pd.DataFrame(index =[feature_list])\n",
    "            for idx,estimator in enumerate(estimators):\n",
    "                    feature_importances['Estimator{}'.format(idx)] = estimators[idx][model_name].feature_importances_\n",
    "            feature_importance_scores[\"{}_{}\".format(model_name, regex_name)] = feature_importances\n",
    "         \n",
    "        filename = 'PickleFiles/CV/{}/{}_cv_estimators.pkl'.format(buffer_size_m, model_name)        \n",
    "        joblib.dump(estimators, filename)\n",
    "        del estimators\n",
    "        \n",
    "error_metric_scores.to_csv('error_metric_scores.csv', index= False)   \n",
    "predictions_df.to_csv('predictions.csv', index= False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_model = joblib.load('PickleFiles/CV/{}/{}_cv_estimators.pkl'.format(200,'linear_regressor'))\n",
    "# xgb_model = joblib.load('PickleFiles/CV/{}/{}_cv_estimators.pkl'.format(200,'xgb_regressor'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the predicted vs actual values from the CV process\n",
    "Within cross validation each data point is included in the test set only once and thus despite their beng multiple cross-validation folds, each true value of Y has only one associated prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, figsize = (12,4))\n",
    "using_datashader(axs[0], Yfull, predictions, 'linear')\n",
    "axs[0].plot([Yfull.min(), Yfull.max()], [Yfull.min(), Yfull.max()], c='k', lw=0.5)\n",
    "axs[0].set_ylabel(\"Predicted Values\", size=10)\n",
    "axs[0].set_xlabel(\"Actual Values\", size=10)\n",
    "axs[0].xaxis.set_tick_params(labelsize='xx-large')\n",
    "axs[0].yaxis.set_tick_params(labelsize='xx-large')\n",
    "axs[0].set_xlim([0, 2000])\n",
    "axs[0].set_ylim([0, 2000])\n",
    "using_datashader(axs[1], Yfull, predictions, 'log')\n",
    "axs[1].plot([Yfull.min(), Yfull.max()], [Yfull.min(), Yfull.max()], c='k', lw=0.5)\n",
    "axs[1].set_ylabel(\"Predicted Values\", size=10)\n",
    "axs[1].set_xlabel(\"Actual Values\", size=10)\n",
    "axs[1].xaxis.set_tick_params(labelsize='xx-large')\n",
    "axs[1].yaxis.set_tick_params(labelsize='xx-large')\n",
    "axs[1].set_xlim([0, 2000])\n",
    "axs[1].set_ylim([0, 2000]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the accuracy scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_metric_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importances from within cross-validation\n",
    "If reporting feature importances from the model, then would use those from fitting the final model on the full dataset. However, this is useful as a measure of the stability of the feature importances that the model reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_df = feature_importance_scores[\"rf_regressor_withsubtypes\"].copy()\n",
    "feature_importances_df.reset_index(inplace=True)\n",
    "feature_importances_df.rename(columns={'level_0':'Variable'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 features for each estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_columns=pd.DataFrame()\n",
    "for column in feature_importances_df.columns[1:]:\n",
    "    this_col = feature_importances_df[['Variable', column]]\n",
    "    important_columns[column] = this_col.sort_values(column, ascending = False)['Variable'].tolist()[0:10]\n",
    "important_columns    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_raw = []\n",
    "pi_ls = []\n",
    "for estimator in estimators[:3]:\n",
    "    pi, pi_raw = find_permutation_importance(estimator['rf_regressor'], Xfull, Yfull, n_iter=3)  \n",
    "    pi_ls.append(pi)\n",
    "    pi_raw.append(pi_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find permutation importance from within Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_columns=pd.DataFrame()\n",
    "for i in list(range(0,len(pi_ls))):\n",
    "    test=pi_ls[i].sort_values('importance', ascending = False)[0:25]\n",
    "    test.reset_index(inplace=True, drop=True)\n",
    "    important_columns[\"PI{}\".format(i)] = test['feature']\n",
    "important_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the error in the predictions broken down by hour and sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all relevant data in one dataframe\n",
    "df =pd.DataFrame({'Predictions': predictions, 'Real_vals':Yfull, 'Hour': data_time_columns['time'],\n",
    "                  'Weekday': data_time_columns['weekday_num'] ,'Sensor_id':sensor_ids, 'AbsolouteError':abs(Yfull-predictions)})\n",
    "# Add hour of week variable\n",
    "df['hour_of_week'] = df.apply (lambda row: label_hour_of_week(row), axis=1)\n",
    "# Sort by this variable\n",
    "df=df.sort_values(by=['Weekday', 'Hour'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to store errors for each hour/sensor\n",
    "hourly_mapes = []\n",
    "hourly_maes = []\n",
    "hourly_mae_stds = []\n",
    "hourly_means= []\n",
    "hourly_stds= []\n",
    "\n",
    "sensorly_mapes =[]\n",
    "sensorly_maes =[]\n",
    "sensorly_means = []\n",
    "\n",
    "hourofweekly_mapes = []\n",
    "hourofweekly_maes = []\n",
    "hourofweekly_means= []\n",
    "hourofweekly_stds= []\n",
    "hourofweekly_mae_stds = []\n",
    "\n",
    "# Loop through the hours and add the results to the list\n",
    "for hour_of_week in df['hour_of_week'].unique():\n",
    "    # print(\"At {} o'clock\".format(hour))\n",
    "    one_hour_of_week = df[df['hour_of_week'] ==hour_of_week]\n",
    "    # print(\"Error is {}% of the average hourly count\".format(round(one_hour['AbsolouteError'].mean()/one_hour['Real_vals'].mean()*100,1)))\n",
    "    hourofweekly_mapes.append(one_hour_of_week['AbsolouteError'].mean()/one_hour_of_week['Real_vals'].mean()*100)\n",
    "    hourofweekly_maes.append(round(one_hour_of_week['AbsolouteError'].mean(),1))\n",
    "    hourofweekly_mae_stds.append(round(one_hour_of_week['AbsolouteError'].std(),1))\n",
    "    hourofweekly_means.append(round(one_hour_of_week['Real_vals'].mean(),1))\n",
    "    hourofweekly_stds.append(round(one_hour_of_week['Real_vals'].std(),1))\n",
    "\n",
    "# Loop through the hours and add the results to the list\n",
    "for hour in range(0,24):\n",
    "    # print(\"At {} o'clock\".format(hour))\n",
    "    one_hour = df[df['Hour'] ==hour]\n",
    "    # print(\"Error is {}% of the average hourly count\".format(round(one_hour['AbsolouteError'].mean()/one_hour['Real_vals'].mean()*100,1)))\n",
    "    hourly_mapes.append(one_hour['AbsolouteError'].mean()/one_hour['Real_vals'].mean()*100)\n",
    "    hourly_maes.append(round(one_hour['AbsolouteError'].mean(),1))\n",
    "    hourly_mae_stds.append(round(one_hour['AbsolouteError'].std(),1))\n",
    "    hourly_means.append(round(one_hour['Real_vals'].mean(),1))\n",
    "    hourly_stds.append(round(one_hour['Real_vals'].std(),1))\n",
    "    \n",
    "# Loop through the sensors and add the results to the list\n",
    "for sensor_id in np.sort(sensor_ids.unique()):\n",
    "    # print(\"At sensor {}\".format(sensor_id))\n",
    "    one_sensor = df[df['Sensor_id'] ==sensor_id]\n",
    "    # print(\"Error is {}% of the average hourly count\".format(round(one_sensor['AbsolouteError'].mean()/one_sensor['Real_vals'].mean()*100,1)))\n",
    "    sensorly_mapes.append(round(one_sensor['AbsolouteError'].mean()/one_sensor['Real_vals'].mean()*100,1))\n",
    "    sensorly_maes.append(round(one_sensor['AbsolouteError'].mean(),1))\n",
    "    sensorly_means.append(one_sensor['Real_vals'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the errors per hour of week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['1am','2am','3am','4am','5am','6am','7am','8am','9am','10am','11am','12',\n",
    "         '1pm','2pm','3pm','4pm','5pm','6pm','7pm','8pm','9pm','10pm','11pm','12',]*7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs =plt.subplots(nrows=3,figsize =(24,20), sharex=True)\n",
    "axs[0].bar(np.sort(df['hour_of_week'].unique()),hourofweekly_means)#,  yerr=hourofweekly_stds  )\n",
    "axs[0].set_title('Mean Values', fontsize=60)\n",
    "axs[1].bar(np.sort(df['hour_of_week'].unique()),hourofweekly_maes)#, yerr=hourofweekly_mae_stds   )\n",
    "axs[1].set_title('Mean Absoloute Error', fontsize=60)\n",
    "axs[2].bar(np.sort(df['hour_of_week'].unique()),hourofweekly_mapes )\n",
    "axs[2].set_title('Mean Absoloute Percentage Error', fontsize=60)\n",
    "# axs[2].tick_params(axis='x')\n",
    "\n",
    "# Removes weird whitespace from the start\n",
    "axs[0].set_xlim([1,len(df['hour_of_week'].unique()[::3])])\n",
    "axs[1].set_xlim([1,len(df['hour_of_week'].unique()[::3])])\n",
    "axs[2].set_xlim([1,len(df['hour_of_week'].unique()[::3])])\n",
    "\n",
    "# Axis labels\n",
    "axs[2].set_xticks(list(range(1,len(labels)))[::6], fontsize=40)\n",
    "axs[2].set_xticklabels(labels[::6], fontsize=40, rotation = 55)\n",
    "\n",
    "params = {'ytick.labelsize': 50}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "for i in range(1,7):\n",
    "    axs[0].axvline(x = 24*i, color = 'black', label = 'axvline - full height')\n",
    "    axs[1].axvline(x = 24*i, color = 'black', label = 'axvline - full height')\n",
    "    axs[2].axvline(x = 24*i, color = 'black', label = 'axvline - full height')\n",
    "    \n",
    "fig.savefig('Figs/Errors/Error_by_hour_of_week.pdf')\n",
    "fig.savefig('Figs/Errors/Error_by_hour_of_week.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot errors by hour of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs =plt.subplots(ncols=3, figsize =(12,3))\n",
    "axs[0].bar(np.sort(df['Hour'].unique()),hourly_mapes )\n",
    "axs[0].set_title('Mean Absoloute Percentage Error');\n",
    "axs[1].bar(np.sort(df['Hour'].unique()),hourly_maes )\n",
    "axs[1].set_title('Mean Absoloute Error')\n",
    "axs[2].bar(np.sort(df['Hour'].unique()),hourly_means )\n",
    "axs[2].set_title('Mean')\n",
    "\n",
    "axs[0].set_xticks(list(range(1,25)))\n",
    "axs[0].set_xticklabels(df['Hour'].unique(), rotation=90, size = 8);\n",
    "axs[1].set_xticks(list(range(1,25)))\n",
    "axs[1].set_xticklabels(df['Hour'].unique(), rotation=90, size = 8);\n",
    "axs[2].set_xticks(list(range(1,25)))\n",
    "axs[2].set_xticklabels(df['Hour'].unique(), rotation=90, size = 8);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the errors by sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read in Melbourne sensor location spatial data\n",
    "melbourne_sensors = pd.read_csv(\"../Data/melbourne_locations.csv\")\n",
    "melbourne_sensors.rename(columns={'sensor_description': 'Name'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensorly_errors_df = pd.DataFrame({'sensor_id':np.sort(sensor_ids.unique()),'MAPE':sensorly_mapes,'MAE':sensorly_maes,\n",
    "                                  'Mean':sensorly_means})\n",
    "melbourne_sensors = pd.merge(sensorly_errors_df, melbourne_sensors, on='sensor_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = cm.LinearColormap([\"green\", \"yellow\", \"red\"], vmin=melbourne_sensors['Mean'].min(),\n",
    "                           vmax=melbourne_sensors['Mean'].max())\n",
    "\n",
    "# Plot\n",
    "melbourne_map = folium.Map(location=[melbourne_sensors.Latitude.mean(),\n",
    "                           melbourne_sensors.Longitude.mean()], zoom_start=14, control_scale=True, min_zoom = 13)\n",
    "\n",
    "for _, row in melbourne_sensors.iterrows():\n",
    "    folium.CircleMarker([row.Latitude, row.Longitude],\n",
    "                      popup=row.sensor_id,\n",
    "                      radius=8,  fill=True, fill_opacity = 1,\n",
    "                      color = linear(row.Mean), fill_color = linear(row.Mean),\n",
    "                      ).add_to(melbourne_map)\n",
    "\n",
    "\n",
    "linear.caption = \"Mean hourly values\"\n",
    "linear.add_to(melbourne_map)\n",
    "melbourne_map\n",
    "\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "img_data = melbourne_map._to_png(5)\n",
    "img = Image.open(io.BytesIO(img_data))\n",
    "img.save('image.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = cm.LinearColormap([\"green\", \"yellow\", \"red\"], vmin=melbourne_sensors['MAPE'].min(), vmax=melbourne_sensors['MAPE'].max())\n",
    "\n",
    "# Plot\n",
    "melbourne_map = folium.Map(location=[melbourne_sensors.Latitude.mean(),\n",
    "                           melbourne_sensors.Longitude.mean()], zoom_start=14, control_scale=True, min_zoom = 13)\n",
    "\n",
    "for _, row in melbourne_sensors.iterrows():\n",
    "    folium.CircleMarker([row.Latitude, row.Longitude],\n",
    "                      popup=row.sensor_id,\n",
    "                      radius=8,  fill=True, fill_opacity = 1,\n",
    "                      color = linear(row.MAPE), fill_color = linear(row.MAPE),\n",
    "                      ).add_to(melbourne_map)\n",
    "\n",
    "\n",
    "linear.caption = \"Mean Absoloute Percentage Error\"\n",
    "linear.add_to(melbourne_map)\n",
    "melbourne_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = cm.LinearColormap([\"green\", \"yellow\", \"red\"], vmin=melbourne_sensors['MAE'].min(), vmax=melbourne_sensors['MAE'].max())\n",
    "\n",
    "# Plot\n",
    "melbourne_map = folium.Map(location=[melbourne_sensors.Latitude.mean(),\n",
    "                           melbourne_sensors.Longitude.mean()], zoom_start=14, control_scale=True, min_zoom = 13)\n",
    "\n",
    "for _, row in melbourne_sensors.iterrows():\n",
    "    folium.CircleMarker([row.Latitude, row.Longitude],\n",
    "                      popup=row.sensor_id,\n",
    "                      radius=8,  fill=True, fill_opacity = 1,\n",
    "                      color = linear(row.MAE), fill_color = linear(row.MAE),\n",
    "                      ).add_to(melbourne_map)\n",
    "\n",
    "\n",
    "linear.caption = \"Mean Absoloute Error for the sensor\"\n",
    "linear.add_to(melbourne_map)\n",
    "melbourne_map"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

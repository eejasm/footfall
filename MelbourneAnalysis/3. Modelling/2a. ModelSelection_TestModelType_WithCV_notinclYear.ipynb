{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection\n",
    "\n",
    "Cross-validation is used here to select the best model. In this script it is used to test the best machine learning model for use in this context.\n",
    "\n",
    "<u>Tests using the following models :</u>\n",
    "* Linear regression\n",
    "* Random forest regressor\n",
    "* XGBoost\n",
    "* Extra Trees Regressor\n",
    "\n",
    "<u> The following variables are included in the model:</u>\n",
    "* Weather variables (rain, temperature, windspeed)\n",
    "* Time variables (Day of week, month, year, time of day, public holiday)\n",
    "* Sensor environment variables (within a 500m buffer of the sensor):\n",
    "    * Betweenness of the street \n",
    "    * Buildings in proximity to the sensor\n",
    "    * Landmarks in proximity to the sensor  \n",
    "    * Furniture in proximity to the sensor    \n",
    "    * Lights in proximity to the sensor   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor \n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import Pipeline\n",
    "import folium\n",
    "import branca.colormap as cm\n",
    "from eli5.sklearn import PermutationImportance\n",
    "import joblib\n",
    "import os\n",
    "import psutil\n",
    "\n",
    "from Functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size_m = 500\n",
    "input_csv =\"../Cleaned_data/FormattedDataForModelling/formatted_data_for_modelling_allsensors_{}.csv\".format(buffer_size_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run models with cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the error metrics for the cross-validation to return, and the parameters of the cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_metrics = ['neg_mean_absolute_error', 'r2', 'neg_root_mean_squared_error', 'neg_mean_absolute_percentage_error']\n",
    "cv_parameters = KFold(n_splits=10, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model_pipeline = Pipeline(steps=[['scaler',StandardScaler()],['linear_regressor',LinearRegression()]])\n",
    "rf_model_pipeline = Pipeline(steps=[['scaler',StandardScaler()],['rf_regressor', RandomForestRegressor(random_state = 1, n_jobs = 10)]])\n",
    "xgb_model_pipeline = Pipeline(steps=[['scaler',StandardScaler()],['xgb_regressor',xgb.XGBRegressor(random_state=1, n_jobs = 16)]])\n",
    "et_model_pipeline = Pipeline(steps=[['scaler',StandardScaler()],['et_regressor',ExtraTreesRegressor (random_state = 1, n_jobs = 16)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {\"linear_regressor\": lr_model_pipeline, \"xgb_regressor\":xgb_model_pipeline, \n",
    "               \"rf_regressor\":rf_model_pipeline}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xfull, Yfull, data_time_columns = prepare_x_y_data(input_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(input_csv)\n",
    "test = pd.merge(test, melbourne_sensors[['Latitude', 'Longitude', 'sensor_id']], on='sensor_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_spatial, X_test_spatial = X.iloc[train_spatial_index,], X.iloc[test_spatial_index,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Prepare your feature matrix with both spatial and non-spatial features\n",
    "X = Xfull  # Assuming X contains both spatial and non-spatial features\n",
    "y = Yfull\n",
    "\n",
    "# Define the spatial coordinates\n",
    "coordinates = test[['Latitude','Longitude']]\n",
    "\n",
    "# Create a StratifiedKFold object for spatial stratification\n",
    "spatial_cv = StratifiedKFold(n_splits=3)\n",
    "\n",
    "# Define the number of temporal blocks for time series splitting\n",
    "n_temporal_blocks = 5\n",
    "\n",
    "# Initialize a Random Forest Regressor model\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "# Define the scoring metric(s) you want to evaluate\n",
    "scoring = ['neg_mean_squared_error']\n",
    "\n",
    "# Initialize an array to store evaluation metrics\n",
    "mse_scores = []\n",
    "\n",
    "# Perform spatially stratified cross-validation with temporal blocking\n",
    "for train_spatial_index, test_spatial_index in spatial_cv.split(X, y):\n",
    "    # Split the data into training and testing sets based on the spatial indices\n",
    "    X_train_spatial, X_test_spatial = X.iloc[train_spatial_index,], X.iloc[test_spatial_index,]\n",
    "    y_train_spatial, y_test_spatial = y[train_spatial_index], y[test_spatial_index]\n",
    "    \n",
    "    # Create a TimeSeriesSplit object for temporal blocking within each spatial fold\n",
    "    temporal_cv = TimeSeriesSplit(n_splits=n_temporal_blocks)\n",
    "    \n",
    "    # Perform temporal blocking within the training set\n",
    "    for train_temporal_index, _ in temporal_cv.split(X_train_spatial):\n",
    "        # Split the training data into training and validation sets based on the temporal indices\n",
    "        X_train, X_val = X_train_spatial.iloc[train_temporal_index,], X_train_spatial.iloc[train_temporal_index+1]\n",
    "        y_train, y_val = y_train_spatial[train_temporal_index], y_train_spatial[train_temporal_index+1]\n",
    "        \n",
    "        # Train your model on the training data\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions on the validation data\n",
    "        y_pred = model.predict(X_val)\n",
    "        \n",
    "        # Calculate the evaluation metric (e.g., mean squared error)\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        mse_scores.append(mse)\n",
    "\n",
    "# Calculate the mean and standard deviation of the evaluation metric\n",
    "mean_mse = np.mean(mse_scores)\n",
    "std_mse = np.std(mse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del Xfull['year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose which month_num and weekday_num option to include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using the dummy variables\n",
    "# Xfull.drop(['Cos_month_num', 'Sin_month_num', 'Cos_weekday_num', 'Sin_weekday_num'], axis=1)\n",
    "# If using the cyclical variables\n",
    "Xfull.drop(['Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday', 'Wednesday',\n",
    "       'month_2', 'month_3', 'month_4', 'month_5', 'month_6', 'month_7',\n",
    "       'month_8', 'month_9', 'month_10', 'month_11', 'month_12'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Temp', 'Humidity', 'Pressure', 'Rain', 'WindSpeed',\n",
      "       'Rainfall amount (millimetres)', 'public_holiday', 'school_holiday',\n",
      "       'betweenness', 'lights', 'street_inf', 'memorials', 'trees',\n",
      "       'bus-stops', 'tram-stops', 'metro-stations', 'taxi-ranks',\n",
      "       'big-car-parks', 'street_inf_Bicycle Rails', 'street_inf_Bollard',\n",
      "       'street_inf_Drinking Fountain', 'street_inf_Floral Crate/Planter Box',\n",
      "       'street_inf_Horse Trough', 'street_inf_Information Pillar',\n",
      "       'street_inf_Litter Bin', 'street_inf_Seat', 'street_inf_Tree Guard',\n",
      "       'landmarks_Community Use', 'landmarks_Mixed Use',\n",
      "       'landmarks_Place Of Assembly', 'landmarks_Place of Worship',\n",
      "       'landmarks_Retail', 'landmarks_Transport', 'landmarks_Education Centre',\n",
      "       'landmarks_Leisure/Recreation', 'landmarks_Office',\n",
      "       'street_inf_Barbeque', 'street_inf_Hoop', 'street_inf_Picnic Setting',\n",
      "       'landmarks_Specialist Residential Accommodation',\n",
      "       'landmarks_Vacant Land', 'landmarks_Purpose Built',\n",
      "       'landmarks_Health Services', 'avg_n_floors', 'buildings_Community Use',\n",
      "       'buildings_Education', 'buildings_Entertainment', 'buildings_Events',\n",
      "       'buildings_Hospital/Clinic', 'buildings_Office', 'buildings_Parking',\n",
      "       'buildings_Public Display Area', 'buildings_Residential',\n",
      "       'buildings_Retail', 'buildings_Storage', 'buildings_Unoccupied',\n",
      "       'buildings_Working', 'buildings_Transport', 'Sin_time', 'Cos_time',\n",
      "       'Sin_month_num', 'Cos_month_num', 'Sin_weekday_num', 'Cos_weekday_num',\n",
      "       'random', 'random_cat'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(Xfull.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear_regressor\n",
      "Ran in 4 minutes\n",
      "xgb_regressor\n",
      "Ran in 123 minutes\n",
      "rf_regressor\n",
      "Ran in 195 minutes\n"
     ]
    }
   ],
   "source": [
    "# Dataframe to store the scores for all the models\n",
    "error_metric_scores = pd.DataFrame()\n",
    "\n",
    "for model_name, model_pipeline in models_dict.items():\n",
    "    print(model_name)\n",
    "    # Use cross_validate to return the error scores associated with this model and this data\n",
    "    start = time()\n",
    "    model_output = cross_validate(model_pipeline, Xfull, Yfull, cv=cv_parameters, scoring=error_metrics, error_score=\"raise\")\n",
    "    end = time()\n",
    "    print('Ran in {} minutes'.format(round((end - start)/60),2))\n",
    "    \n",
    "    # Formulate the different error scores into a dataframe\n",
    "    error_metrics_df =pd.DataFrame({'mae': round(abs(model_output['test_neg_mean_absolute_error'].mean()),2), \n",
    "                  'mape': round(abs(model_output['test_neg_mean_absolute_percentage_error'].mean()),2),\n",
    "                  'r2': round(abs(model_output['test_r2'].mean()),2), \n",
    "                  'rmse': round(abs(model_output['test_neg_root_mean_squared_error'].mean()),2)},\n",
    "                 index =[model_name])\n",
    "        \n",
    "    # Add evaluation metric scores for this model to the dataframe containing the metrics for each model\n",
    "    error_metric_scores = error_metric_scores.append(error_metrics_df)\n",
    "    # Save error scores for this distance to file\n",
    "    #error_metrics_df.to_csv('Results/CV/ComparingModels/{}_{}m_error_metric_scores.csv'.format(model_name,buffer_size_m),index=False)    \n",
    "\n",
    "# Save dataframes of error metrics for each buffer distance \n",
    "#error_metric_scores.to_csv('Results/CV/ComparingModels/comparingmodels_error_metric_scores.csv')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print table showing error metrics associated with each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mae</th>\n",
       "      <th>mape</th>\n",
       "      <th>r2</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>linear_regressor</th>\n",
       "      <td>261.31</td>\n",
       "      <td>1.459393e+16</td>\n",
       "      <td>0.47</td>\n",
       "      <td>358.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb_regressor</th>\n",
       "      <td>112.80</td>\n",
       "      <td>4.262695e+15</td>\n",
       "      <td>0.85</td>\n",
       "      <td>191.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_regressor</th>\n",
       "      <td>73.33</td>\n",
       "      <td>2.087694e+15</td>\n",
       "      <td>0.91</td>\n",
       "      <td>146.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     mae          mape    r2    rmse\n",
       "linear_regressor  261.31  1.459393e+16  0.47  358.50\n",
       "xgb_regressor     112.80  4.262695e+15  0.85  191.91\n",
       "rf_regressor       73.33  2.087694e+15  0.91  146.02"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_metric_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df= error_metric_scores.copy()\n",
    "# df = df.reindex(['linear_regressor', 'rf_regressor', 'xgb_regressor'])"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

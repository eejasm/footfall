{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor \n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import Pipeline\n",
    "import folium\n",
    "import branca.colormap as cm\n",
    "from eli5.sklearn import PermutationImportance\n",
    "import joblib\n",
    "import os\n",
    "import psutil\n",
    "\n",
    "from Functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_x_y_data(buffer_size_m):\n",
    "    # Read in formatted data\n",
    "    data = pd.read_csv(\"../Cleaned_data/FormattedDataForModelling/formatted_data_for_modelling_allsensors_{}.csv\".format(buffer_size_m), \n",
    "                       index_col = False)\n",
    "\n",
    "    ### Delete unneeded columns - we currently include data from all sensors (even incomplete ones)\n",
    "    sensor_ids = data['sensor_id']\n",
    "    data = data.drop(['sensor_id'],axis=1) # don't want this included\n",
    "    # Get rid of columns in which none of the sensors have a value\n",
    "    for column in data.columns:\n",
    "        if np.nanmax(data[column]) ==0:\n",
    "            del data[column]\n",
    "\n",
    "    # Remove the heading column (using subheadings going forward ) \n",
    "    regex_pattern = 'buildings$|street_inf$|landmarks$'\n",
    "    data = data[data.columns.drop(list(data.filter(regex=regex_pattern)))].copy()\n",
    "\n",
    "    #################################\n",
    "    # Deal with date based variables\n",
    "    #################################\n",
    "    ### Store the (non Sin/Cos) time columns and then remove them (Need them later to segment the results by hour of the day)\n",
    "    data_time_columns = data[['day_of_month_num', 'time', 'weekday_num', 'time_of_day']]\n",
    "\n",
    "    ###  Option 1 - Sin/Cos variables\n",
    "    # data_time_columns = data[['day_of_month_num', 'time', 'weekday_num', 'time_of_day']]\n",
    "    # data = data.drop(['day_of_month_num', 'time', 'weekday_num', 'time_of_day','year', 'month','day', 'datetime', 'month_num'],axis=1)\n",
    "\n",
    "    ### Option 2 - Create Dummy Variables\n",
    "    data = data.drop(['datetime',  'time', 'time_of_day', \"day_of_month_num\" , 'weekday_num','month_num',\n",
    "                     # 'Sin_month_num', 'Cos_month_num', 'Sin_weekday_num', 'Cos_weekday_num',\n",
    "                     ],axis=1)\n",
    "\n",
    "    ### Add a random variable (to compare performance of other variables against)\n",
    "    rng = np.random.RandomState(seed=42)\n",
    "    data['random'] = np.random.random(size=len(data))\n",
    "    data[\"random_cat\"] = rng.randint(3, size=data.shape[0])\n",
    "\n",
    "    ## Prepare data for modelling \n",
    "    ### Split into predictor/predictand variables\n",
    "    Xfull = data.drop(['hourly_counts'], axis =1)\n",
    "    Yfull = data['hourly_counts'].values\n",
    "    return Xfull, Yfull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model_pipeline = Pipeline(steps=[['scaler',StandardScaler()],['linear_regressor',LinearRegression()]])\n",
    "rf_model_pipeline = Pipeline(steps=[['scaler',StandardScaler()],['rf_regressor', RandomForestRegressor(random_state = 1, n_jobs = 10)]])\n",
    "xgb_model_pipeline = Pipeline(steps=[['scaler',StandardScaler()],['xgb_regressor',xgb.XGBRegressor(random_state=1, n_jobs = 16)]])\n",
    "et_model_pipeline = Pipeline(steps=[['scaler',StandardScaler()],['et_regressor',ExtraTreesRegressor (random_state = 1, n_jobs = 16)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_metrics = ['neg_mean_absolute_error', 'r2', 'neg_root_mean_squared_error', 'neg_mean_absolute_percentage_error']\n",
    "cv_parameters = KFold(n_splits=10, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'Temp', 'Humidity', 'Pressure', 'Rain', 'WindSpeed',\n",
       "       'Rainfall amount (millimetres)', 'public_holiday', 'school_holiday',\n",
       "       'betweenness', 'lights', 'memorials', 'trees', 'bus-stops',\n",
       "       'tram-stops', 'metro-stations', 'taxi-ranks', 'big-car-parks',\n",
       "       'street_inf_Bicycle Rails', 'street_inf_Bollard',\n",
       "       'street_inf_Drinking Fountain', 'street_inf_Floral Crate/Planter Box',\n",
       "       'street_inf_Horse Trough', 'street_inf_Information Pillar',\n",
       "       'street_inf_Litter Bin', 'street_inf_Seat', 'street_inf_Tree Guard',\n",
       "       'landmarks_Community Use', 'landmarks_Mixed Use',\n",
       "       'landmarks_Place Of Assembly', 'landmarks_Place of Worship',\n",
       "       'landmarks_Retail', 'landmarks_Transport', 'landmarks_Education Centre',\n",
       "       'landmarks_Leisure/Recreation', 'landmarks_Office',\n",
       "       'street_inf_Barbeque', 'street_inf_Hoop', 'street_inf_Picnic Setting',\n",
       "       'landmarks_Specialist Residential Accommodation',\n",
       "       'landmarks_Vacant Land', 'landmarks_Purpose Built',\n",
       "       'landmarks_Health Services', 'avg_n_floors',\n",
       "       'buildings_Commercial Accommodation', 'buildings_Community Use',\n",
       "       'buildings_Educational/Research',\n",
       "       'buildings_Entertainment/Recreation - Indoor',\n",
       "       'buildings_Equipment Installation', 'buildings_Hospital/Clinic',\n",
       "       'buildings_House/Townhouse', 'buildings_Manufacturing',\n",
       "       'buildings_Office', 'buildings_Parking - Commercial Covered',\n",
       "       'buildings_Performances, Conferences, Ceremonies',\n",
       "       'buildings_Public Display Area', 'buildings_Residential Apartment',\n",
       "       'buildings_Retail - Shop', 'buildings_Retail - Showroom',\n",
       "       'buildings_Storage', 'buildings_Student Accommodation',\n",
       "       'buildings_Unoccupied - Under Construction',\n",
       "       'buildings_Unoccupied - Under Demolition/Condemned',\n",
       "       'buildings_Unoccupied - Under Renovation',\n",
       "       'buildings_Unoccupied - Unused', 'buildings_Workshop/Studio',\n",
       "       'buildings_Parking - Private Covered', 'buildings_Transport',\n",
       "       'buildings_Retail - Cars', 'buildings_Wholesale',\n",
       "       'buildings_Institutional Accommodation', 'buildings_Retail - Stall',\n",
       "       'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday', 'Wednesday',\n",
       "       'month_2', 'month_3', 'month_4', 'month_5', 'month_6', 'month_7',\n",
       "       'month_8', 'month_9', 'month_10', 'month_11', 'month_12', 'Sin_time',\n",
       "       'Cos_time', 'random', 'random_cat'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Xfull, Yfull = prepare_x_y_data(buffer_size_m)\n",
    "Xfull.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running cross_validate\n",
      "ran cross_validate\n",
      "Ran in 170 minutes\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'PickleFiles/CV/500/rf_regressor_error_metrics_500m.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_273652/312232393.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Add evaluation metric scores for this model to the dataframe containing the metrics for each model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0merror_metric_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_metric_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_metrics_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0merror_metrics_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PickleFiles/CV/{}/{}_error_metrics_{}m.csv'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer_size_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbuffer_size_m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0merror_metric_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error_metric_scores.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/footfall_ml/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3480\u001b[0m             \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3481\u001b[0m             \u001b[0mescapechar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mescapechar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3482\u001b[0;31m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3483\u001b[0m         )\n\u001b[1;32m   3484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/footfall_ml/lib/python3.7/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1103\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         )\n\u001b[0;32m-> 1105\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/footfall_ml/lib/python3.7/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m         ) as handles:\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/footfall_ml/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'PickleFiles/CV/500/rf_regressor_error_metrics_500m.csv'"
     ]
    }
   ],
   "source": [
    "# Dataframe to store the scores for each model\n",
    "error_metric_scores = pd.DataFrame()\n",
    "\n",
    "# model_name = {\"xgb_regressor\":xgb_model_pipeline}\n",
    "model = rf_model_pipeline\n",
    "model_name = 'rf_regressor'\n",
    "regex_name = 'withsubtypes'\n",
    "regex = 'buildings$|furniture$|landmarks$'\n",
    "\n",
    "for buffer_size_m in [500]:\n",
    "    Xfull, Yfull = prepare_x_y_data(buffer_size_m)\n",
    "\n",
    "    start = time()\n",
    "    print(\"running cross_validate\")\n",
    "    model_output = cross_validate(rf_model_pipeline, Xfull, Yfull, cv=cv_parameters, scoring=error_metrics, error_score=\"raise\")\n",
    "    print(\"ran cross_validate\")   \n",
    "    end = time()\n",
    "    print('Ran in {} minutes'.format(round((end - start)/60),2))\n",
    "    \n",
    "    error_metrics_df =pd.DataFrame({'mae': round(abs(model_output['test_neg_mean_absolute_error'].mean()),2), \n",
    "                  'mape': round(abs(model_output['test_neg_mean_absolute_percentage_error'].mean()),2),\n",
    "                  'r2': round(abs(model_output['test_r2'].mean()),2), \n",
    "                  'rmse': round(abs(model_output['test_neg_root_mean_squared_error'].mean()),2)},\n",
    "                 index =[\"{}\".format(buffer_size_m)])\n",
    "    \n",
    "    \n",
    "    # Add evaluation metric scores for this model to the dataframe containing the metrics for each model\n",
    "    error_metric_scores = error_metric_scores.append(error_metrics_df)\n",
    "    error_metrics_df.to_csv('PickleFiles/CV/{}/{}_error_metrics_{}m.csv'.format(buffer_size_m, model_name,buffer_size_m),index=False)    \n",
    "        \n",
    "error_metric_scores.to_csv('error_metric_scores.csv')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mae</th>\n",
       "      <th>mape</th>\n",
       "      <th>r2</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>61.11</td>\n",
       "      <td>1.480037e+15</td>\n",
       "      <td>0.94</td>\n",
       "      <td>125.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mae          mape    r2    rmse\n",
       "500  61.11  1.480037e+15  0.94  125.58"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_metric_scores"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate temporally\n",
    "In this script, validation is performed temporally.  \n",
    "To do this, the final 10% of data is used for testing, and the first 90% is used for training.  \n",
    "\n",
    "Potential issues: the final portion of time might exhibit different patterns to the rest of the time.  \n",
    "There are some sensors that only start operating towards the end, so the model would have no chance to learn about their behaviour.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error, r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.colors as colors\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import time as time\n",
    "#  Spatial packages\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "import contextily as cx\n",
    "# Machine learning packages\n",
    "# import xgboost as xgb\n",
    "\n",
    "# Custom function for neg_mean_absolute_percentage_error\n",
    "def neg_mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return -100 * np.mean(np.abs((y_true - y_pred) / y_true))\n",
    "\n",
    "from Functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the necessary data\n",
    "#### Get testing and training data\n",
    "Specify buffer size (as there are different versions of the data created with different buffer sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "buffer_size_m = 500\n",
    "input_csv =\"../Cleaned_data/FormattedDataForModelling/formatted_data_for_modelling_allsensors_{}.csv\".format(buffer_size_m)\n",
    "Xfull, Yfull, data_time_columns = prepare_x_y_data(input_csv)\n",
    "Xfull= Xfull[0:2129007]\n",
    "Yfull= Yfull[0:2129007]\n",
    "data_time_columns = data_time_columns[0:2129007]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop one version of the time variables (either cyclical or dummy versions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using the dummy variables\n",
    "# Xfull.drop(['Cos_month_num', 'Sin_month_num', 'Cos_weekday_num', 'Sin_weekday_num'], axis=1)\n",
    "# If using the cyclical variables\n",
    "Xfull.drop(['Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday', 'Wednesday',\n",
    "       'month_2', 'month_3', 'month_4', 'month_5', 'month_6', 'month_7',\n",
    "       'month_8', 'month_9', 'month_10', 'month_11', 'month_12'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete the year variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "del Xfull['year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the sensor locations (this is needed if splitting the data spatially in cross validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "melbourne_sensors = pd.read_csv(\"../Data/FootfallData/melbourne_locations.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get as series the sensor ids and datetimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sensor_ids = pd.read_csv(input_csv)['sensor_id']\n",
    "datetimes = pd.read_csv(input_csv)['datetime']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the error metrics for the cross-validation to return, and the parameters of the cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_metrics = ['neg_mean_absolute_error', 'r2', 'neg_root_mean_squared_error', 'neg_mean_absolute_percentage_error']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up model pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_pipeline = Pipeline(steps=[['scaler',StandardScaler()],['rf_regressor', RandomForestRegressor(random_state = 1, n_jobs = 10)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {\"rf_regressor\":rf_model_pipeline}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation manually "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = Xfull[0:int(len(Xfull)*0.9)].index.tolist()\n",
    "test_index = Xfull[int(len(Xfull)*0.9):].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to store the scores\n",
    "mae_scores = []\n",
    "rmse_scores= []\n",
    "r2_scores= []\n",
    "neg_mae_scores = []\n",
    "# Lists to store predicetd and actual values\n",
    "predicted_values=[]\n",
    "observed_values = []\n",
    "# List to store the datetimes\n",
    "datetimes_used = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "\n",
    "# Get train and testing data for this fold\n",
    "print(f\"train index: {len(train_index)}\")\n",
    "print(f\"test index: {len(test_index)}\")\n",
    "print(f\"percentage of data used as testing: {round(len(test_index)/len(train_index)*100,1)}\")\n",
    "\n",
    "X_train, X_test = Xfull.iloc[train_index], Xfull.iloc[test_index]\n",
    "y_train, y_test = Yfull[train_index], Yfull[test_index]\n",
    "# Fit the model on the training data\n",
    "rf_model_pipeline.fit(X_train, y_train)\n",
    "# Use it to make predictions on the testing data, and store these\n",
    "y_pred = rf_model_pipeline.predict(X_test)\n",
    "predicted_values.append(y_pred)\n",
    "# Store the datetimes\n",
    "datetimes_used.append(datetimes[train_index])\n",
    "# Store the actual values for the testing data\n",
    "observed_values.append(y_test)\n",
    "# Calculate the error metrics for this fold and append to the scores lists\n",
    "mae_scores.append(mean_absolute_error(y_test, y_pred))\n",
    "r2_scores.append(r2_score(y_test, y_pred))\n",
    "rmse_scores.append(mean_squared_error(y_test, y_pred, squared=False))\n",
    "neg_mae_scores = [-score for score in mae_scores]        \n",
    "\n",
    "end = time()\n",
    "print('Ran cross_val_predict in {} minutes'.format(round((end - start)/60),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_values_all = []\n",
    "observed_values_all= []\n",
    "for i in range(len(predicted_values)):\n",
    "    for j in range(len(predicted_values[i])):\n",
    "        observed_values_all.append(observed_values[i][j])\n",
    "        predicted_values_all.append(predicted_values[i][j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean absoloute error: {mae_scores}\")\n",
    "print(f\"Mean R2: {r2_scores}\")\n",
    "print(f\"Mean RMSE: {rmse_scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datashader as ds\n",
    "from datashader.mpl_ext import dsshow\n",
    "fig, axs = plt.subplots(ncols=2, figsize = (12,4))\n",
    "\n",
    "# Plot with linear scale\n",
    "using_datashader(axs[0], y_test, predicted_values_all, 'linear')\n",
    "axs[0].plot([Yfull.min(), Yfull.max()], [Yfull.min(), Yfull.max()], c='k', lw=0.5)\n",
    "axs[0].set_ylabel(\"Predicted Values\", size=10)\n",
    "axs[0].set_xlabel(\"Actual Values\", size=10)\n",
    "#axs[0].set_xlim([0, 2000])\n",
    "#axs[0].set_ylim([0, 2000])\n",
    "axs[0].tick_params(axis='both', which='major', labelsize=8)\n",
    "\n",
    "# Plot with log scale\n",
    "using_datashader(axs[1], y_test, predicted_values_all, 'log')\n",
    "axs[1].plot([Yfull.min(), Yfull.max()], [Yfull.min(), Yfull.max()], c='k', lw=0.5)\n",
    "axs[1].set_ylabel(\"Predicted Values\", size=10)\n",
    "axs[1].set_xlabel(\"Actual Values\", size=10)\n",
    "# axs[1].set_xlim([0, 2000])\n",
    "# axs[1].set_ylim([0, 2000]);\n",
    "axs[1].tick_params(axis='both', which='major', labelsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_parameters =x KFolxd(n_splits=2, random_state=1, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
